{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This file creates the word2vec model for the papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import pymongo\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# gensim\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "import gensim\n",
    "\n",
    "# sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# logging for gensim (set to INFO)\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import offline\n",
    "py.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "import colorlover as cl\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pymongo version: 3.2.2\n",
      "NLTK version: 3.2.5\n",
      "Gensim version: 3.3.0\n",
      "Regex version: 2.2.1\n",
      "Plotly version: 2.2.3\n",
      "Python 3.6.4 :: Anaconda custom (64-bit)\r\n"
     ]
    }
   ],
   "source": [
    "packages = (('Pymongo', pymongo), ('NLTK', nltk), ('Gensim', gensim),\n",
    "           ('Regex', re),('Plotly',py))\n",
    "\n",
    "for package in packages:\n",
    "    print('{0} version: {1}'.format(package[0],package[1].__version__))\n",
    "    \n",
    "!Python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Subset of Data From Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cs_papers', 'math_papers', 'stat_papers']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient(port=12345) # this is the port set by the SSH tunnel\n",
    "db = client.research_papers\n",
    "db.collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Individual Topic Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 1132 articles.\n"
     ]
    }
   ],
   "source": [
    "topic_of_interest = 'math'\n",
    "\n",
    "databases = {'cs':db.cs_papers.find(), 'stat':db.stat_papers.find(), 'math':db.math_papers.find()}\n",
    "\n",
    "# to pull all papers in the same area\n",
    "stat_subj = re.compile(r'stat\\.|math\\.pr|math\\.st')\n",
    "math_subj = re.compile(r'math\\.')\n",
    "cs_subj = re.compile(r'cs\\.')\n",
    "topic_labels = {'cs':cs_subj, 'stat':stat_subj, 'math':math_subj}\n",
    "\n",
    "all_papers = []\n",
    "\n",
    "for topic in databases.keys():\n",
    "    \n",
    "    database = databases[topic]\n",
    "    subset = 0\n",
    "    \n",
    "    current_paper = database\n",
    "\n",
    "    for pape in current_paper:    \n",
    "\n",
    "        subjects = pape['subject']\n",
    "        \n",
    "        in_topic = False\n",
    "        topic = topic_labels[topic_of_interest]\n",
    "        \n",
    "        for subj in subjects:\n",
    "            if re.search(topic, subj):\n",
    "                in_topic = True\n",
    "            \n",
    "            \n",
    "        if in_topic:\n",
    "            article = pape['article']\n",
    "            if article:\n",
    "                if len(article) > 5000:\n",
    "                    all_papers.append(pape)\n",
    "                    subset+=1\n",
    "                \n",
    "print('There are a total of {0} articles.'.format(len(all_papers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word cid it the top word in all classes and seems to stand for random mathematical things, like: fractions, matrices, not equal to, and the box at the end of a proof to signify it is the end of the proof.  Because of this I will take it out of the set.\n",
    "\n",
    "Also ligatures appear a lot in the translation, the following set was created from the Wikipedea page on ligatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ligatures = {'êœ²':'AA', 'êœ³':'aa', 'Ã†':'AE', 'Ã¦':'ae', 'êœ´':'AO', 'êœµ':'ao',\n",
    "            'êœ¶':'AU', 'êœ·':'au', 'êœ¸':'AV', 'êœ¹':'av', 'êœº':'AV', 'êœ»':'av',\n",
    "            'êœ¼':'AY', 'êœ½':'ay', 'ğŸ™°':'et', 'ï¬€':'ff', 'ï¬ƒ':'ffi', 'ï¬„':'ffl', \n",
    "            'ï¬':'fi', 'ï¬‚':'fl', 'Å’':'OE', 'Å“':'oe', 'ê':'OO', 'ê':'oo', \n",
    "            'ï¬†':'st', 'êœ¨':'TZ', 'êœ©':'tz', 'áµ«':'ue', 'ê ':'VY', 'ê¡':'vy'}\n",
    "\n",
    "for lig in ligatures:\n",
    "    re_lig = re.compile(lig)\n",
    "\n",
    "    for pape in all_papers:\n",
    "        pape['article'] = re.sub(re_lig, ligatures[lig], pape['article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_cid = re.compile('cid')\n",
    "et_al_cid = re.compile('et al')\n",
    "\n",
    "for pape in all_papers:\n",
    "    pape['article'] = re.sub(re_cid, ' ', pape['article'])\n",
    "    pape['article'] = re.sub(et_al_cid, '', pape['article'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computer Science: 11,743,082 words\n",
    "\n",
    "Statistics: 7,794,464 words\n",
    "\n",
    "Mathematics: 9,544,541 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = [pape['article'] for pape in all_papers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9544541 words total.\n"
     ]
    }
   ],
   "source": [
    "total_word_count = 0\n",
    "for text in all_text:\n",
    "    total_word_count += len(text.split())\n",
    "\n",
    "print('There are {0} words total.'.format(total_word_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minor Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, text in enumerate(all_text):\n",
    "    cv = re.compile('crossvalidation')\n",
    "    quote = re.compile('â€')\n",
    "    \n",
    "    all_text[index] = re.sub(cv,'cross validation',text)\n",
    "    all_text[index] = re.sub(quote,'',text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = stopwords.words('english')\n",
    "\n",
    "texts = [[word for word in pape.split() if word not in stoplist] for pape in all_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(input_list,n):\n",
    "    '''\n",
    "        Finds all n-groupings of word in text.  Returns\n",
    "        a string with word1_word2_...\n",
    "    '''\n",
    "    ngrams = list(zip(*[input_list[i:] for i in range(n)]))\n",
    "      \n",
    "    return [*map('_'.join, ngrams)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_trigrams = []\n",
    "for text in texts:\n",
    "    texts_trigrams.append(text + ngrams(text,2) + ngrams(text,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-07 21:30:47,496 : INFO : collecting all words and their counts\n",
      "2018-03-07 21:30:47,496 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-03-07 21:30:54,616 : INFO : collected 7289546 word types from a corpus of 18566082 raw words and 1132 sentences\n",
      "2018-03-07 21:30:54,616 : INFO : Loading a fresh vocabulary\n",
      "2018-03-07 21:30:56,940 : INFO : min_count=30 retains 32662 unique words (0% of original 7289546, drops 7256884)\n",
      "2018-03-07 21:30:56,941 : INFO : min_count=30 leaves 7436304 word corpus (40% of original 18566082, drops 11129778)\n",
      "2018-03-07 21:30:57,038 : INFO : deleting the raw counts dictionary of 7289546 items\n",
      "2018-03-07 21:30:57,152 : INFO : sample=0.001 downsamples 29 most-common words\n",
      "2018-03-07 21:30:57,153 : INFO : downsampling leaves estimated 6812659 word corpus (91.6% of prior 7436304)\n",
      "2018-03-07 21:30:57,286 : INFO : estimated required memory for 32662 words and 100 dimensions: 42460600 bytes\n",
      "2018-03-07 21:30:57,287 : INFO : resetting layer weights\n",
      "2018-03-07 21:30:57,602 : INFO : training model with 4 workers on 32662 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-03-07 21:30:58,611 : INFO : EPOCH 1 - PROGRESS: at 23.41% examples, 1394805 words/s, in_qsize 7, out_qsize 0\n",
      "2018-03-07 21:30:59,618 : INFO : EPOCH 1 - PROGRESS: at 45.32% examples, 1398288 words/s, in_qsize 7, out_qsize 0\n",
      "2018-03-07 21:31:00,623 : INFO : EPOCH 1 - PROGRESS: at 67.05% examples, 1371684 words/s, in_qsize 7, out_qsize 0\n",
      "2018-03-07 21:31:01,632 : INFO : EPOCH 1 - PROGRESS: at 85.42% examples, 1302400 words/s, in_qsize 7, out_qsize 0\n",
      "2018-03-07 21:31:02,380 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-07 21:31:02,381 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-07 21:31:02,394 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-07 21:31:02,404 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-07 21:31:02,405 : INFO : EPOCH - 1 : training on 18566082 raw words (6106130 effective words) took 4.8s, 1272106 effective words/s\n",
      "2018-03-07 21:31:03,418 : INFO : EPOCH 2 - PROGRESS: at 22.44% examples, 1345000 words/s, in_qsize 7, out_qsize 0\n",
      "2018-03-07 21:31:04,424 : INFO : EPOCH 2 - PROGRESS: at 44.79% examples, 1381188 words/s, in_qsize 7, out_qsize 0\n",
      "2018-03-07 21:31:05,426 : INFO : EPOCH 2 - PROGRESS: at 68.64% examples, 1401933 words/s, in_qsize 7, out_qsize 0\n",
      "2018-03-07 21:31:06,428 : INFO : EPOCH 2 - PROGRESS: at 92.40% examples, 1408982 words/s, in_qsize 7, out_qsize 0\n",
      "2018-03-07 21:31:06,726 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-07 21:31:06,731 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-07 21:31:06,742 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-07 21:31:06,752 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-07 21:31:06,753 : INFO : EPOCH - 2 : training on 18566082 raw words (6105378 effective words) took 4.3s, 1405144 effective words/s\n",
      "2018-03-07 21:31:07,761 : INFO : EPOCH 3 - PROGRESS: at 23.41% examples, 1395316 words/s, in_qsize 7, out_qsize 0\n",
      "2018-03-07 21:31:08,766 : INFO : EPOCH 3 - PROGRESS: at 45.85% examples, 1416264 words/s, in_qsize 7, out_qsize 0\n",
      "2018-03-07 21:31:09,769 : INFO : EPOCH 3 - PROGRESS: at 69.35% examples, 1424134 words/s, in_qsize 7, out_qsize 0\n",
      "2018-03-07 21:31:10,774 : INFO : EPOCH 3 - PROGRESS: at 93.55% examples, 1427721 words/s, in_qsize 7, out_qsize 0\n",
      "2018-03-07 21:31:11,021 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-07 21:31:11,026 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-07 21:31:11,037 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-07 21:31:11,046 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-07 21:31:11,047 : INFO : EPOCH - 3 : training on 18566082 raw words (6106727 effective words) took 4.3s, 1422882 effective words/s\n",
      "2018-03-07 21:31:12,053 : INFO : EPOCH 4 - PROGRESS: at 22.97% examples, 1381304 words/s, in_qsize 7, out_qsize 0\n",
      "2018-03-07 21:31:13,056 : INFO : EPOCH 4 - PROGRESS: at 44.96% examples, 1395271 words/s, in_qsize 7, out_qsize 0\n",
      "2018-03-07 21:31:14,058 : INFO : EPOCH 4 - PROGRESS: at 68.46% examples, 1404245 words/s, in_qsize 7, out_qsize 0\n",
      "2018-03-07 21:31:15,062 : INFO : EPOCH 4 - PROGRESS: at 92.31% examples, 1411390 words/s, in_qsize 8, out_qsize 0\n",
      "2018-03-07 21:31:15,361 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-07 21:31:15,366 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-07 21:31:15,377 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-07 21:31:15,386 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-07 21:31:15,387 : INFO : EPOCH - 4 : training on 18566082 raw words (6106264 effective words) took 4.3s, 1407831 effective words/s\n",
      "2018-03-07 21:31:16,393 : INFO : EPOCH 5 - PROGRESS: at 22.88% examples, 1381950 words/s, in_qsize 7, out_qsize 0\n",
      "2018-03-07 21:31:17,395 : INFO : EPOCH 5 - PROGRESS: at 45.14% examples, 1398688 words/s, in_qsize 6, out_qsize 1\n",
      "2018-03-07 21:31:18,399 : INFO : EPOCH 5 - PROGRESS: at 68.20% examples, 1398294 words/s, in_qsize 7, out_qsize 0\n",
      "2018-03-07 21:31:19,400 : INFO : EPOCH 5 - PROGRESS: at 91.96% examples, 1406177 words/s, in_qsize 7, out_qsize 0\n",
      "2018-03-07 21:31:19,712 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-07 21:31:19,716 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-07 21:31:19,727 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-07 21:31:19,737 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-07 21:31:19,737 : INFO : EPOCH - 5 : training on 18566082 raw words (6106335 effective words) took 4.3s, 1405039 effective words/s\n",
      "2018-03-07 21:31:19,738 : INFO : training on a 92830410 raw words (30530834 effective words) took 22.1s, 1379270 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(texts_trigrams, size=100, window=10, min_count=30, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if topic_of_interest == 'math':\n",
    "    filename = 'Word2Vec_Math.pkl'\n",
    "elif topic_of_interest == 'stat':\n",
    "    filename = 'Word2Vec_Stats.pkl'\n",
    "else:\n",
    "    filename = 'Word2Vec_CS.pkl'\n",
    "    \n",
    "# with open(filename,'wb') as pickle_out:\n",
    "#     pickle.dump(model, pickle_out)\n",
    "\n",
    "with open(filename,'rb') as pickle_in:\n",
    "    model = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('institute', <gensim.models.keyedvectors.Vocab at 0x1a441062e8>),\n",
       " ('technology', <gensim.models.keyedvectors.Vocab at 0x1a44106be0>),\n",
       " ('cambridge', <gensim.models.keyedvectors.Vocab at 0x1a44106dd8>),\n",
       " ('email', <gensim.models.keyedvectors.Vocab at 0x1a4410a5c0>),\n",
       " ('c', <gensim.models.keyedvectors.Vocab at 0x1a44108198>),\n",
       " ('e', <gensim.models.keyedvectors.Vocab at 0x1a44108080>),\n",
       " ('n', <gensim.models.keyedvectors.Vocab at 0x1a4410e668>),\n",
       " ('h', <gensim.models.keyedvectors.Vocab at 0x1a4410ceb8>),\n",
       " ('v', <gensim.models.keyedvectors.Vocab at 0x1a4410c0b8>),\n",
       " ('x', <gensim.models.keyedvectors.Vocab at 0x1a4410ce48>)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_wv = list(model.wv.vocab.items())\n",
    "words_wv[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_words = ['ab_testing', 'accuracy', 'activation_function', 'adaboost', 'adaptive_boosting', 'adjusted', \n",
    "                     'agglomerative', 'aggregate', 'aggregates', 'aggregating', 'analysis_pca', 'analyst', \n",
    "                     'auc', 'average_linkage', 'backpropagation', 'bag_of_words', 'bag_words', 'bagging', 'batch', \n",
    "                     'bayesian', 'belief', 'bernoulli', 'bias', 'biased', 'big_data', 'binomial', \n",
    "                     'boost', 'bootstrap', 'brute_force', 'cart', 'classification', 'classifier', 'cluster', 'cod', \n",
    "                     'complete_linkage', 'complexity', 'component_analysis', 'computational', 'concavity', \n",
    "                     'conditional_distribution', 'confidence', 'confusion_matrix', 'consistency', 'constrained', \n",
    "                     'convex', 'convex_optimization', 'correlated', 'correlation', 'cosine_distance', \n",
    "                     'cosine_similarity', 'cost_function', 'coupling', 'cross_validate', 'cross_validation', \n",
    "                     'curse_dimensionality', 'curse_of_dimensionality', 'data', 'data_engineering', 'data_mining', \n",
    "                     'data_processing', 'data_set', 'dataset', 'dbscan', 'decision_boundary', 'decision_tree', \n",
    "                     'deep_learning', 'derive', 'deterministic', 'dimensionality', 'dimensionality_reduction', \n",
    "                     'dirichlet', 'discrete', 'downsampled', 'dx', 'eigenvalue', 'eigenvector', 'elastic_net',\n",
    "                     'engineer', 'ensemble', 'entropy', 'euclidean_distance', 'f1', 'f1_score', 'f_score', \n",
    "                     'factorization', 'fbeta_score', 'feature_extraction', 'feature_representation', \n",
    "                     'feature_selection', 'feature_space', 'feature_vector', 'features', 'feedforward', 'fold', \n",
    "                     'fpr', 'fscore', 'functionality', 'gaussian', 'gaussian_model', 'gaussians', 'general_model', \n",
    "                     'generalized_linear_model', 'generative', 'gradient', 'gradient_boosting', 'gradient_descent', \n",
    "                     'greedy', 'hidden_layer', 'hierarchical', 'hierarchical_agglomerative_clustering', \n",
    "                     'hierarchical_clustering', 'high_confidence', 'inertia', 'information_entropy', \n",
    "                     'interconnected', 'interpolation', 'interpretability', 'jaccard_distance', 'jacobian', \n",
    "                     'k_iterations', 'k_means', 'kernel', 'kmeans', 'knn', 'l_norm', 'l_regularization', \n",
    "                     'labeled_data', 'lambda', 'language_processing', 'lasso', 'latent_dirichlet_allocation', \n",
    "                     'lda', 'learning_algorithms', 'learning_rate', 'likelihood', 'likelihood_estimation', \n",
    "                     'linear_approximation', 'linear_combination', 'linear_model', 'linear_regression', \n",
    "                     'linear_term', 'linearly_dependent', 'linearly_independent', 'linkage', 'log_e', \n",
    "                     'log_likelihood', 'log_odd', 'logarithm', 'logistic_regression', 'logit', 'loss_function', \n",
    "                     'machine_learning', 'manhattan_distance', 'markov_chain', 'mathematical_model', 'matrix', \n",
    "                     'matrix_factorization', 'maximum_likelihood', 'mean', 'mean_squared_error', 'measure', 'metric', \n",
    "                     'mini_batch', 'minibatch', 'minimization', 'missing_data', 'mle', 'model', 'model_based', \n",
    "                     'model_complexity', 'model_predictive', 'model_training', 'modeling', 'monte_carlo', \n",
    "                     'multiple_correspondence_analysis', 'n_gram', 'naive_bayes', 'natural_language_processing', \n",
    "                     'nearest_neighbor', 'nearestneighbor', 'negative_loglikelihood', 'neighborhood', \n",
    "                     'neural_network', 'ngram', 'nlp', 'node', 'nonlinear', 'nonlinearity', 'norm', \n",
    "                     'normalization', 'normalize', 'ols', 'optimal_solutions', 'optimization', \n",
    "                     'ordinary_least_squares', 'orthogonal', 'outlier', 'parameter_estimation', 'parameterization', \n",
    "                     'parametric_model', 'pattern_recognition', 'patterns', 'pca', 'performance_metric', \n",
    "                     'pipeline', 'poisson', 'polynomial_regression', 'pooling', 'posterior', 'precision', \n",
    "                     'prediction', 'predictive', 'predictor', 'principal_component', \n",
    "                     'principal_component_analysis', 'prior', 'apriori', 'probability_distribution', 'process', \n",
    "                     'projected', 'proof', 'prune', 'python', 'random_forest', 'random_variable', 'recall', \n",
    "                     'receiver_operating_characteristic', 'regression_model', 'regularization', \n",
    "                     'regularization_parameter', 'ridge_regression', 'roc', 'sampling', 'semisupervised', \n",
    "                     'sensitivity', 'sigmoid', 'simple_linear', 'simulation_results', 'single_linkage', \n",
    "                     'singular_value', 'singular_value_decomposition', 'skewed', 'space', 'sparse', \n",
    "                     'specificity', 'spectral_clustering', 'stack', 'statistical_model', 'stemming', 'step', \n",
    "                     'step_size', 'stochastic_gradient', 'stochastic_gradient_descent', 'stop_word', \n",
    "                     'stopping_criterion', 'subsampling', 'sufficient', 'supervised_learning', 'support_vector', \n",
    "                     'support_vector_machines', 'svd', 'svm', 'target', 'tend', 'test_data', 'threshold', \n",
    "                     'time_series', 'time_step', 'tokenization', 'tokenize', 'topic_modeling', 'total_variation', \n",
    "                     'tpr', 'train', 'trained_model', 'trained_models', 'training', 'training_data', \n",
    "                     'training_model', 'training_validation', 'trajectory', 'tree', 'treelike', 'tsne', 'unbiased', \n",
    "                     'uncorrelated', 'uniformly', 'unsupervised', 'unsupervised_learning', 'upsampling', \n",
    "                     'validate', 'validation', 'variance_reduction', 'vector_regression', 'visualization', 'ward', \n",
    "                     'ward_linkage', 'weight_vector', 'word_embedding', 'wordvec', 'zero']\n",
    "\n",
    "interesting_words = np.array(interesting_words)\n",
    "\n",
    "characters = ['ğœ', 'ğ', 'âˆ', 'ğ›', 'ğ‘', 'Î¹', 'Î', 'ğŒ', 'ğšª', 'Î¥', 'ğœ‘', 'Î ', 'ğœ…', 'ğœ¸', 'Ï‘', 'ğ†', 'â¿', 'ğ›Š', 'ğœ‚', \n",
    "              'ğ›˜', 'ğ›»', 'ğ„', 'ğ', 'ğ˜', 'ğœ‰', 'ğ›Œ', 'Î²', 'ğ', 'ğœ·', 'â‰¤', 'ğœƒ', 'ğœ¹', 'Î›', 'âˆ’âˆ', 'âˆ€', 'ğ›', 'Ï‚', 'ğ›¿', 'ğ›', \n",
    "              'âˆ€', 'ğ', 'Î©', 'ğ››', 'ğ™', 'ğ›„', 'ğ›š', 'âˆˆ', 'ğ›', 'â‰ª', 'â‡', 'ğ›¾', 'ğŠ', 'âŠ•', 'Ç«', 'Î¸', ' ', 'âˆ', 'Î¶', 'ğœŒ', \n",
    "              'âˆ…', 'Î“', 'Ï†', 'ğœ¿', 'ğ›½', 'ğ•', 'ğœš', 'ğ›Ÿ', 'ğ“', 'Ï', 'Î»', 'Ïƒ', 'âˆª', '<', 'ğ›–', 'ğ›†', 'Î±', 'ğ›·', 'Î¿', 'Ï‡', \n",
    "              'ğœŠ', 'ğˆ', 'â‰©', 'ğ›', 'â†”', 'ğ›¡', 'Î·', 'Îœ', 'âŸ¾', 'âŠ¤', 'wt', 'ğœ“', 'xi', 'âˆ´', 'âŠ†', 'Î—', 'ğ›ƒ', 'Î–', 'ğœ˜', \n",
    "              'â¤ƒ', 'ğ› ', 'Îº', 'Î¾', 'Ï‰', 'â‰¨', 'â„', 'ğœ•', 'Î', 'Î¨', 'â‰ˆ', 'Ï„', 'ğ›', 'ğ›‘', 'ğ‚', 'ğœ½', 'ğ›¥', 'â‡”', 'ğ›‡', 'âˆ¬', \n",
    "              'âŠƒ', 'ğœ’', 'ğ›‚', 'ğœ™', 'ğœ¼', 'Î´', 'ğœ¶', 'ğ›¬', '>', 'ğ’', 'ğœˆ', 'ğ›ˆ', 'ğ›¹', 'Î£', 'Ïˆ', 'ğ›‹', 'ğœ', 'Î™', 'â‰¡', 'Î¼', \n",
    "              'Î½', 'Î‘', 'ğ”', 'ğ€', 'ğœ', 'â¤‡', 'ğ›”', 'âŠ‡', 'â‡’', 'ğƒ', 'ğœ»', 'ğ›œ', 'âŠ‰', 'âŠˆ', 'âˆ‰', 'â‰ƒ', 'st', 'Î¡', 'ğ›“', 'ğœ‹', \n",
    "              'ğœ†', 'Î¤', 'ğœ‡', 'ğœ€', 'Âµ', 'ğœ¾', 'Ï€', 'âˆ‹', 'âŠ‚', 'âˆ«', 'Î’', 'âŠ…', 'Î§', 'âŠ„', 'ğœ', 'âˆµ', 'ğœ›', 'Â±', 'Â·', 'ğ›‰', \n",
    "              'ğœ', 'ğ', 'ğ›™', 'âˆ®', 'ğ‰', 'Î³', 'ğ›¼', 'âˆ†', 'Î”', 'ğœ„', 'ğ›—', 'ÎŸ', 'âˆ©', 'Îš', 'ğœº', 'ğœ—', 'rmÃ—n', 'ğœ', 'Î˜', \n",
    "              'âˆ‚', 'Î¦', 'âˆ§', 'ğœ–', 'ğ›¤', 'ğ‹', 'ğ‡', 'Îµ', 'Î•', 'Ï…', 'âˆ‘', 'ğ›…', 'ğ›’', 'â‰«', 'ğ…', 'ğ›•' ]\n",
    "\n",
    "characters = np.array(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('solve_problem', 0.9721465706825256),\n",
       " ('integrability_condition', 0.9716504812240601),\n",
       " ('rigid_body', 0.9677146673202515),\n",
       " ('prove_convergence', 0.9664644002914429),\n",
       " ('mean_variance', 0.9654554128646851),\n",
       " ('differential_operator', 0.965217113494873),\n",
       " ('cf_eg', 0.965144693851471),\n",
       " ('small_parameter', 0.9648418426513672),\n",
       " ('piecewise_constant', 0.964563250541687),\n",
       " ('point_process', 0.9642618894577026)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at all models and topics learned in class\n",
    "model.wv.most_similar('cost_function', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5237479631530428"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('model', 'system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 similar words to Î¹ are.\n",
      "           word  similarity score\n",
      "0            Â¯e          0.736334\n",
      "1            âˆ¼â†’          0.706884\n",
      "2    involution          0.698789\n",
      "3   epimorphism          0.696101\n",
      "4      commutes          0.693671\n",
      "5       functor          0.674511\n",
      "6  monomorphism          0.666959\n",
      "7     bialgebra          0.659829\n",
      "8       sending          0.659221\n",
      "9     bijection          0.653210\n",
      "\n",
      "The top 10 similar words to Ï‘ are.\n",
      "          word  similarity score\n",
      "0       solves          0.621823\n",
      "1           âˆÏ‰          0.619247\n",
      "2     fulfills          0.608248\n",
      "3  subsolution          0.607115\n",
      "4           uÎ·          0.605175\n",
      "5           Ï‰t          0.603780\n",
      "6           vÂ·          0.600897\n",
      "7           aÏˆ          0.599313\n",
      "8   fulfilling          0.596572\n",
      "9           Îºt          0.593771\n",
      "\n",
      "The top 10 similar words to Î² are.\n",
      "  word  similarity score\n",
      "0    Î±          0.670674\n",
      "1   sÎ²          0.662106\n",
      "2   hÎ²          0.637006\n",
      "3   Î²c          0.633028\n",
      "4   âˆ’Î²          0.630898\n",
      "5   aÎ²          0.617219\n",
      "6   lÎ²          0.610192\n",
      "7   xÎ²          0.605828\n",
      "8   eÎ±          0.603662\n",
      "9   Î²t          0.584290\n",
      "\n",
      "The top 10 similar words to â‰¤ are.\n",
      "           word  similarity score\n",
      "0             â‰¥          0.616332\n",
      "1           max          0.596098\n",
      "2           sup          0.582501\n",
      "3    inequality          0.579558\n",
      "4             âˆ’          0.556959\n",
      "5       summing          0.555059\n",
      "6       claimed          0.548348\n",
      "7  consequently          0.543840\n",
      "8  inequalities          0.538644\n",
      "9     similarly          0.538037\n",
      "\n",
      "The top 10 similar words to âˆ€ are.\n",
      "       word  similarity score\n",
      "0         âˆƒ          0.740335\n",
      "1        âˆ€t          0.681654\n",
      "2        âˆ€x          0.673902\n",
      "3        âˆ€z          0.599892\n",
      "4        uÂ·          0.592558\n",
      "5        vÂ·          0.578797\n",
      "6  fulfills          0.572657\n",
      "7        yâˆ—          0.568747\n",
      "8        âˆ€i          0.567254\n",
      "9       inâˆ—          0.563074\n",
      "\n",
      "The top 10 similar words to Ï‚ are.\n",
      "  word  similarity score\n",
      "0   mÏƒ          0.737927\n",
      "1   Ï‡t          0.662034\n",
      "2   hÏƒ          0.658649\n",
      "3   eÏƒ          0.654193\n",
      "4   Î´s          0.650550\n",
      "5   Î³Ï„          0.647431\n",
      "6   âˆ’Ïƒ          0.644091\n",
      "7   Î»Ïƒ          0.633679\n",
      "8   ËœÏƒ          0.632906\n",
      "9   Ïƒr          0.632169\n",
      "\n",
      "The top 10 similar words to âˆ€ are.\n",
      "       word  similarity score\n",
      "0         âˆƒ          0.740335\n",
      "1        âˆ€t          0.681654\n",
      "2        âˆ€x          0.673902\n",
      "3        âˆ€z          0.599892\n",
      "4        uÂ·          0.592558\n",
      "5        vÂ·          0.578797\n",
      "6  fulfills          0.572657\n",
      "7        yâˆ—          0.568747\n",
      "8        âˆ€i          0.567254\n",
      "9       inâˆ—          0.563074\n",
      "\n",
      "The top 10 similar words to âˆˆ are.\n",
      "             word  similarity score\n",
      "0         belongs          0.639008\n",
      "1           every          0.638702\n",
      "2          belong          0.634258\n",
      "3         clearly          0.615766\n",
      "4  representative          0.608353\n",
      "5               âŠ†          0.608232\n",
      "6       arbitrary          0.598518\n",
      "7          unique          0.591278\n",
      "8            pick          0.586739\n",
      "9        whenever          0.586326\n",
      "\n",
      "The top 10 similar words to â‰ª are.\n",
      "      word  similarity score\n",
      "0        â‰«          0.710990\n",
      "1       cÎ´          0.656360\n",
      "2        â‰          0.615907\n",
      "3     olog          0.583604\n",
      "4       mÏ‡          0.576131\n",
      "5       Î´n          0.571140\n",
      "6      log          0.556359\n",
      "7  claimed          0.553916\n",
      "8       cÂµ          0.551771\n",
      "9  summing          0.541413\n",
      "\n",
      "The top 10 similar words to Ç« are.\n",
      "  word  similarity score\n",
      "0   âˆ’Ç«          0.623796\n",
      "1   tÇ«          0.591534\n",
      "2   oÇ«          0.576674\n",
      "3   mÇ«          0.568677\n",
      "4   cÇ«          0.553476\n",
      "5   gÇ«          0.541031\n",
      "6   dÇ«          0.532435\n",
      "7   aÇ«          0.505812\n",
      "8   fÇ«          0.499682\n",
      "9   hÇ«          0.496452\n",
      "\n",
      "The top 10 similar words to Î¸ are.\n",
      "    word  similarity score\n",
      "0     hÎ¸          0.673581\n",
      "1     dÎ¸          0.645524\n",
      "2     cÎ¸          0.627747\n",
      "3     Â¯Î¸          0.620307\n",
      "4     Î¸t          0.595160\n",
      "5    cos          0.592072\n",
      "6     xÎ¸          0.584961\n",
      "7     Î¸âˆ’          0.583223\n",
      "8  angle          0.582879\n",
      "9     Ï†Î¸          0.582183\n",
      "\n",
      "The top 10 similar words to âˆ are.\n",
      "          word  similarity score\n",
      "0           âˆ’âˆ          0.728585\n",
      "1           Â±âˆ          0.628140\n",
      "2        tends          0.611188\n",
      "3      letting          0.607096\n",
      "4     infinity          0.601959\n",
      "5     diverges          0.594920\n",
      "6        limit          0.593339\n",
      "7            â†“          0.555318\n",
      "8  asymptotics          0.537222\n",
      "9    converges          0.536779\n",
      "\n",
      "The top 10 similar words to Î¶ are.\n",
      "       word  similarity score\n",
      "0        Î¶p          0.627305\n",
      "1        Î¶âˆ’          0.590337\n",
      "2        dÎ¶          0.570160\n",
      "3        Î¶Î¶          0.568353\n",
      "4        Î¶i          0.558014\n",
      "5        Î¶n          0.543665\n",
      "6        âˆ’Î¶          0.489731\n",
      "7        Î¾â‰¤          0.468979\n",
      "8        nÎ¶          0.454384\n",
      "9  lifetime          0.448824\n",
      "\n",
      "The top 10 similar words to âˆ… are.\n",
      "        word  similarity score\n",
      "0          âˆ©          0.761393\n",
      "1      empty          0.700884\n",
      "2        Ï‰bx          0.629290\n",
      "3          âˆª          0.622254\n",
      "4          âŠ†          0.596312\n",
      "5  singleton          0.596269\n",
      "6          âŠƒ          0.566023\n",
      "7  redundant          0.565838\n",
      "8        fin          0.563713\n",
      "9        enq          0.563266\n",
      "\n",
      "The top 10 similar words to Ï† are.\n",
      "  word  similarity score\n",
      "0    Ïˆ          0.679237\n",
      "1   uÏ†          0.652432\n",
      "2   Ï†âˆ’          0.641162\n",
      "3   Ï†x          0.558855\n",
      "4   Ï†p          0.556446\n",
      "5   Ï†t          0.548327\n",
      "6   Î»Ï†          0.539006\n",
      "7   Ï†b          0.538491\n",
      "8   dÏ†          0.536821\n",
      "9  câˆc          0.534752\n",
      "\n",
      "The top 10 similar words to Ï are.\n",
      "  word  similarity score\n",
      "0   Ïâ€²          0.649389\n",
      "1   Ïa          0.641189\n",
      "2   Ïâˆ—          0.611914\n",
      "3   rÏ          0.611914\n",
      "4   bÏ          0.604737\n",
      "5   Ïâˆ’          0.597679\n",
      "6   Ïi          0.592535\n",
      "7   âˆ†Ï          0.591477\n",
      "8   pÏ          0.586750\n",
      "9   aÏ          0.586586\n",
      "\n",
      "The top 10 similar words to Î» are.\n",
      "  word  similarity score\n",
      "0   Î»âˆ—          0.754863\n",
      "1   pÎ»          0.733722\n",
      "2   Î»m          0.725812\n",
      "3   aÎ»          0.660904\n",
      "4   Î»â€²          0.655265\n",
      "5   sÎ»          0.654823\n",
      "6   Î»i          0.652626\n",
      "7   xÎ»          0.649316\n",
      "8   Î»âˆ’          0.644431\n",
      "9   ÏƒÎ»          0.639038\n",
      "\n",
      "The top 10 similar words to Ïƒ are.\n",
      "  word  similarity score\n",
      "0   Ïƒâˆ’          0.750072\n",
      "1   Ïƒâ€²          0.733863\n",
      "2   xÏƒ          0.700406\n",
      "3   Ï„v          0.671971\n",
      "4   wÏƒ          0.665849\n",
      "5   sÏƒ          0.665539\n",
      "6   ËœÏƒ          0.650579\n",
      "7   ÏˆÏƒ          0.633280\n",
      "8   pÏƒ          0.628009\n",
      "9   Ïƒi          0.624269\n",
      "\n",
      "The top 10 similar words to âˆª are.\n",
      "       word  similarity score\n",
      "0     empty          0.653223\n",
      "1         âˆ…          0.622254\n",
      "2       fin          0.620028\n",
      "3  disjoint          0.615351\n",
      "4      Î²dâˆ’k          0.607390\n",
      "5         âŠ†          0.604531\n",
      "6     union          0.580639\n",
      "7   contain          0.579216\n",
      "8    domcrn          0.577022\n",
      "9      clet          0.569823\n",
      "\n",
      "The top 10 similar words to Î± are.\n",
      "  word  similarity score\n",
      "0   sÎ±          0.674387\n",
      "1    Î²          0.670674\n",
      "2   ÏˆÎ±          0.652372\n",
      "3   cÎ±          0.650707\n",
      "4   eÎ±          0.645081\n",
      "5   Î±r          0.642044\n",
      "6   rÎ±          0.627264\n",
      "7   âˆ’Î±          0.621385\n",
      "8   wÎ±          0.612190\n",
      "9   aÎ±          0.610223\n",
      "\n",
      "The top 10 similar words to Ï‡ are.\n",
      "          word  similarity score\n",
      "0    character          0.766174\n",
      "1           mÏ‡          0.688830\n",
      "2   characters          0.685982\n",
      "3           Ï‡âˆ’          0.632181\n",
      "4    conductor          0.623834\n",
      "5  constituent          0.611336\n",
      "6           Ï‡k          0.610093\n",
      "7           dÏ‡          0.593904\n",
      "8           eÏ•          0.590792\n",
      "9           qe          0.576289\n",
      "\n",
      "The top 10 similar words to â†” are.\n",
      "          word  similarity score\n",
      "0     coloring          0.671275\n",
      "1   bijections          0.662823\n",
      "2    decorated          0.653021\n",
      "3        arrow          0.635395\n",
      "4  assignments          0.612995\n",
      "5          web          0.612891\n",
      "6    bijection          0.609489\n",
      "7      digraph          0.607805\n",
      "8     labelled          0.605142\n",
      "9      diagram          0.599238\n",
      "\n",
      "The top 10 similar words to Î· are.\n",
      "  word  similarity score\n",
      "0   Î·t          0.685223\n",
      "1   âˆ’Î·          0.669655\n",
      "2   Î·â€²          0.647688\n",
      "3   rÎ·          0.635915\n",
      "4   gÎ·          0.568797\n",
      "5   pÎ·          0.555729\n",
      "6   ËœÎ·          0.546849\n",
      "7   dÎ·          0.541547\n",
      "8   Î·d          0.525427\n",
      "9   Î·âˆ’          0.516584\n",
      "\n",
      "The top 10 similar words to xi are.\n",
      "   word  similarity score\n",
      "0    yi          0.830265\n",
      "1   xiâˆ’          0.637908\n",
      "2    Î´i          0.631669\n",
      "3    ti          0.629322\n",
      "4    yj          0.628955\n",
      "5   Î´xi          0.627740\n",
      "6    xj          0.624596\n",
      "7   dxi          0.618876\n",
      "8   eix          0.612210\n",
      "9  fixi          0.601325\n",
      "\n",
      "The top 10 similar words to âŠ† are.\n",
      "          word  similarity score\n",
      "0     nonempty          0.719485\n",
      "1       subset          0.686447\n",
      "2            âŠ‡          0.657186\n",
      "3      subsets          0.643176\n",
      "4        dense          0.628310\n",
      "5  ultrafilter          0.626893\n",
      "6          fin          0.608793\n",
      "7            âˆˆ          0.608232\n",
      "8            âˆª          0.604531\n",
      "9            âˆ…          0.596312\n",
      "\n",
      "The top 10 similar words to Îº are.\n",
      "       word  similarity score\n",
      "0        rÎº          0.725675\n",
      "1        gÎº          0.667806\n",
      "2        cÎº          0.624911\n",
      "3        hÎº          0.592303\n",
      "4  cardinal          0.570299\n",
      "5   forcing          0.530587\n",
      "6        Îºv          0.489670\n",
      "7        Îºâˆ’          0.481816\n",
      "8        Î»âˆ—          0.475870\n",
      "9        xÎº          0.464340\n",
      "\n",
      "The top 10 similar words to Î¾ are.\n",
      "  word  similarity score\n",
      "0   âˆ’Î¾          0.682541\n",
      "1   Î¾n          0.681997\n",
      "2   aÎ¾          0.673099\n",
      "3   Î¾Î¾          0.645283\n",
      "4   pÎ¾          0.632835\n",
      "5   Î¾w          0.632684\n",
      "6   gÎ¾          0.623773\n",
      "7   Î¾d          0.613543\n",
      "8   Î¾m          0.611775\n",
      "9   yÎ¾          0.603981\n",
      "\n",
      "The top 10 similar words to Ï‰ are.\n",
      "     word  similarity score\n",
      "0      Ï‰â€²          0.700905\n",
      "1      cÏ‰          0.685246\n",
      "2      Î³Ï‰          0.672761\n",
      "3      Ï‰t          0.659230\n",
      "4  domain          0.637586\n",
      "5      rÏ‰          0.626318\n",
      "6      Ï‰m          0.606869\n",
      "7      dÏ‰          0.605132\n",
      "8      âˆ‚Ï‰          0.602991\n",
      "9      xÏ‰          0.596121\n",
      "\n",
      "The top 10 similar words to â‰ˆ are.\n",
      "         word  similarity score\n",
      "0      errors          0.689835\n",
      "1   estimator          0.677406\n",
      "2           âˆš          0.617077\n",
      "3       ratio          0.616054\n",
      "4  iterations          0.612752\n",
      "5       error          0.601867\n",
      "6   estimated          0.595341\n",
      "7    accuracy          0.592342\n",
      "8          oÎµ          0.592045\n",
      "9    expected          0.584417\n",
      "\n",
      "The top 10 similar words to Ï„ are.\n",
      "  word  similarity score\n",
      "0   eÏ„          0.720914\n",
      "1   aÏ„          0.696061\n",
      "2   iÏ„          0.657862\n",
      "3   dÏ„          0.647658\n",
      "4   pÏ„          0.642882\n",
      "5   cÏ„          0.631473\n",
      "6   gÏ„          0.628326\n",
      "7   Ï„âˆ’          0.617465\n",
      "8   ÏƒÏ„          0.608684\n",
      "9   âˆ’Ï„          0.605589\n",
      "\n",
      "The top 10 similar words to â‡” are.\n",
      "  word  similarity score\n",
      "0   â‡â‡’          0.792765\n",
      "1   Î±a          0.598434\n",
      "2    âˆƒ          0.597514\n",
      "3   âˆ€a          0.595895\n",
      "4  axa          0.587006\n",
      "5   âˆƒx          0.583722\n",
      "6    â‡’          0.580966\n",
      "7   Ï•a          0.575135\n",
      "8   aÎ¸          0.568946\n",
      "9   âŠ†c          0.565859\n",
      "\n",
      "The top 10 similar words to âŠƒ are.\n",
      "       word  similarity score\n",
      "0         âŠ‡          0.634123\n",
      "1         âˆ©          0.594893\n",
      "2         âŠ”          0.594655\n",
      "3         âŠ‚          0.571634\n",
      "4         âˆ…          0.566023\n",
      "5        Ë˜d          0.556825\n",
      "6         âŠ†          0.553846\n",
      "7  nonempty          0.553200\n",
      "8       clx          0.552389\n",
      "9        fâˆ’          0.551962\n",
      "\n",
      "The top 10 similar words to Î´ are.\n",
      "  word  similarity score\n",
      "0   âˆ’Î´          0.676170\n",
      "1   cÎ´          0.619598\n",
      "2   oÎ´          0.617629\n",
      "3   eÎ´          0.605171\n",
      "4   Î´âˆ’          0.602610\n",
      "5   Î´â€²          0.583458\n",
      "6   hÎ´          0.570513\n",
      "7   sÎ´          0.565603\n",
      "8   dÎ´          0.543551\n",
      "9   nÎ´          0.534912\n",
      "\n",
      "The top 10 similar words to Ïˆ are.\n",
      "       word  similarity score\n",
      "0         Ï†          0.679237\n",
      "1         Ï•          0.645713\n",
      "2        Ïˆt          0.611307\n",
      "3        hÏˆ          0.605866\n",
      "4        dÏˆ          0.601198\n",
      "5        Ïˆi          0.592352\n",
      "6        ËœÏˆ          0.588731\n",
      "7  latitude          0.571662\n",
      "8        Ïˆx          0.562094\n",
      "9        Ïˆâ€²          0.561961\n",
      "\n",
      "The top 10 similar words to â‰¡ are.\n",
      "         word  similarity score\n",
      "0         mod          0.798843\n",
      "1      modulo          0.530201\n",
      "2          Î·a          0.468713\n",
      "3          âˆ†Î¸          0.463092\n",
      "4           Â±          0.460159\n",
      "5  congruence          0.452432\n",
      "6          pÎ·          0.452356\n",
      "7        indf          0.444714\n",
      "8        even          0.437004\n",
      "9    assuming          0.426882\n",
      "\n",
      "The top 10 similar words to Î½ are.\n",
      "  word  similarity score\n",
      "0    Âµ          0.670820\n",
      "1   cÎ½          0.635015\n",
      "2   iÎ½          0.632041\n",
      "3   kÎ½          0.594369\n",
      "4   Î½k          0.590075\n",
      "5   âˆ’Î½          0.587860\n",
      "6   Î½âˆ’          0.582827\n",
      "7   mÎ½          0.574730\n",
      "8   ËœÎ½          0.557247\n",
      "9   Âµâˆ’          0.536129\n",
      "\n",
      "The top 10 similar words to âŠ‡ are.\n",
      "          word  similarity score\n",
      "0           ig          0.680276\n",
      "1           oâ€²          0.666825\n",
      "2            â‰º          0.657505\n",
      "3            âŠ†          0.657186\n",
      "4           Â¯l          0.643033\n",
      "5            âŠƒ          0.634123\n",
      "6  ultrafilter          0.608729\n",
      "7   maximality          0.606752\n",
      "8           ff          0.603959\n",
      "9           fâ€²          0.598733\n",
      "\n",
      "The top 10 similar words to â‡’ are.\n",
      "          word  similarity score\n",
      "0  implication          0.763022\n",
      "1     converse          0.633296\n",
      "2    assertion          0.629729\n",
      "3         item          0.614169\n",
      "4            â‡”          0.580966\n",
      "5          iii          0.570957\n",
      "6           râ€¢          0.568983\n",
      "7           ii          0.568475\n",
      "8            âœ·          0.562557\n",
      "9          Ï‰bx          0.557741\n",
      "\n",
      "The top 10 similar words to â‰ƒ are.\n",
      "         word  similarity score\n",
      "0         âˆ¼âˆ’â†’          0.763976\n",
      "1  isomorphic          0.737291\n",
      "2          âŠ—k          0.732951\n",
      "3           â‹Š          0.697284\n",
      "4        dimc          0.692975\n",
      "5        exti          0.691966\n",
      "6         hom          0.688756\n",
      "7         ËœeÃ—          0.685524\n",
      "8         ind          0.668002\n",
      "9          âŠ—r          0.666980\n",
      "\n",
      "The top 10 similar words to st are.\n",
      "  word  similarity score\n",
      "0   tt          0.649406\n",
      "1   ts          0.621141\n",
      "2   ht          0.617883\n",
      "3   mt          0.577243\n",
      "4   yt          0.562119\n",
      "5   rt          0.549973\n",
      "6   th          0.549306\n",
      "7  min          0.546017\n",
      "8  max          0.540415\n",
      "9  spt          0.532851\n",
      "\n",
      "The top 10 similar words to Âµ are.\n",
      "      word  similarity score\n",
      "0        Î½          0.670820\n",
      "1       bÂµ          0.669404\n",
      "2       Âµy          0.639440\n",
      "3       Âµâˆ’          0.639225\n",
      "4  measure          0.636376\n",
      "5       Âµâ€²          0.634166\n",
      "6       ÂµÎ»          0.631691\n",
      "7       Î»Âµ          0.612782\n",
      "8       qÂµ          0.605245\n",
      "9       xÂµ          0.598756\n",
      "\n",
      "The top 10 similar words to Ï€ are.\n",
      "    word  similarity score\n",
      "0     âˆ’Ï€          0.703616\n",
      "1     Î»Ï€          0.610085\n",
      "2     Ï€z          0.581008\n",
      "3   qpÎ³q          0.574631\n",
      "4     Ï€s          0.561173\n",
      "5     Ï€x          0.556485\n",
      "6     Ï€â€²          0.552960\n",
      "7     Ï€i          0.551533\n",
      "8    cos          0.547363\n",
      "9  angle          0.539638\n",
      "\n",
      "The top 10 similar words to âˆ‹ are.\n",
      "        word  similarity score\n",
      "0          âˆ¶          0.680967\n",
      "1    mapping          0.636938\n",
      "2         rÃ—          0.632488\n",
      "3     kerâˆ‡lâŠ¥          0.627052\n",
      "4  injection          0.625974\n",
      "5         âˆx          0.620512\n",
      "6      sends          0.611488\n",
      "7        shy          0.603604\n",
      "8         Ï‰Ã—          0.598808\n",
      "9         Ï•Â·          0.596474\n",
      "\n",
      "The top 10 similar words to âŠ‚ are.\n",
      "         word  similarity score\n",
      "0    nonempty          0.685934\n",
      "1      subset          0.654469\n",
      "2        open          0.648947\n",
      "3   contained          0.631896\n",
      "4  containing          0.629897\n",
      "5      closed          0.627091\n",
      "6  collection          0.621671\n",
      "7    supports          0.617090\n",
      "8     closure          0.607716\n",
      "9       dense          0.600550\n",
      "\n",
      "The top 10 similar words to Â± are.\n",
      "        word  similarity score\n",
      "0         oa          0.602959\n",
      "1         mâˆ’          0.588890\n",
      "2         Â±q          0.577208\n",
      "3         âˆ’âˆ’          0.570805\n",
      "4        odd          0.563884\n",
      "5         cÂ±          0.554767\n",
      "6         âˆ’m          0.554101\n",
      "7  congruent          0.549774\n",
      "8         ÂµÂ±          0.548853\n",
      "9      signs          0.538858\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 similar words to Â· are.\n",
      "           word  similarity score\n",
      "0            oâˆ†          0.540753\n",
      "1       factors          0.487453\n",
      "2       reduced          0.485936\n",
      "3           nÏ‰x          0.476819\n",
      "4     quasinorm          0.454436\n",
      "5           rkv          0.450011\n",
      "6    commutator          0.436760\n",
      "7           âˆ’kx          0.436159\n",
      "8            Âµg          0.431898\n",
      "9  equivalently          0.431580\n",
      "\n",
      "The top 10 similar words to Î³ are.\n",
      "  word  similarity score\n",
      "0   bÎ³          0.698846\n",
      "1   Î³â€²          0.670804\n",
      "2   Î³âˆ’          0.660261\n",
      "3   hÎ³          0.645874\n",
      "4   cÎ³          0.641119\n",
      "5   pÎ³          0.627400\n",
      "6   Î³Î³          0.626574\n",
      "7   fÎ³          0.626045\n",
      "8   xÎ³          0.612566\n",
      "9   gÎ³          0.605494\n",
      "\n",
      "The top 10 similar words to âˆ† are.\n",
      "         word  similarity score\n",
      "0          âˆ†âˆ’          0.576360\n",
      "1          âˆ†â€²          0.557063\n",
      "2  simplicial          0.497065\n",
      "3          hâˆ†          0.491847\n",
      "4      kleene          0.489392\n",
      "5          âˆ†k          0.485938\n",
      "6       facet          0.478481\n",
      "7      facets          0.470009\n",
      "8     polygon          0.464160\n",
      "9          âˆ†p          0.462774\n",
      "\n",
      "The top 10 similar words to âˆ© are.\n",
      "           word  similarity score\n",
      "0             âˆ…          0.761393\n",
      "1  intersection          0.667693\n",
      "2     contained          0.615281\n",
      "3             âŠƒ          0.594893\n",
      "4         empty          0.586701\n",
      "5          recf          0.579836\n",
      "6             âŠ†          0.566544\n",
      "7             âŠ‚          0.566090\n",
      "8        belong          0.563886\n",
      "9      nonempty          0.561750\n",
      "\n",
      "The top 10 similar words to rmÃ—n are.\n",
      "        word  similarity score\n",
      "0       rnÃ—n          0.786722\n",
      "1      rankx          0.731866\n",
      "2       cnÃ—n          0.593912\n",
      "3         ax          0.586062\n",
      "4       rqÃ—q          0.573702\n",
      "5        nÃ—n          0.564749\n",
      "6   matrices          0.554389\n",
      "7  transpose          0.547756\n",
      "8  submatrix          0.547370\n",
      "9         nÃ—          0.534124\n",
      "\n",
      "The top 10 similar words to âˆ‚ are.\n",
      "  word  similarity score\n",
      "0   âˆ‚x          0.762979\n",
      "1   âˆ‚t          0.738740\n",
      "2   âˆ‚s          0.718554\n",
      "3  âˆ‚xi          0.701075\n",
      "4   âˆ‚y          0.671877\n",
      "5   âˆ‚z          0.642757\n",
      "6  âˆ‚zi          0.637549\n",
      "7   âˆ‚v          0.632356\n",
      "8   âˆ‚f          0.623424\n",
      "9   âˆ‚a          0.621953\n",
      "\n",
      "The top 10 similar words to âˆ§ are.\n",
      "        word  similarity score\n",
      "0          âˆ¨          0.558370\n",
      "1         tÏ†          0.506920\n",
      "2        âˆƒyx          0.461914\n",
      "3        eqn          0.455326\n",
      "4         â„“p          0.452366\n",
      "5         tm          0.451459\n",
      "6  similarly          0.444784\n",
      "7       dhmi          0.443499\n",
      "8        dxa          0.439441\n",
      "9  recalling          0.435987\n",
      "\n",
      "The top 10 similar words to Îµ are.\n",
      "  word  similarity score\n",
      "0   âˆ’Îµ          0.741874\n",
      "1   gÎµ          0.673555\n",
      "2   pÎµ          0.653027\n",
      "3   yÎµ          0.620848\n",
      "4   uÎµ          0.610001\n",
      "5   hÎµ          0.604460\n",
      "6   tÎµ          0.598627\n",
      "7   dÎµ          0.594220\n",
      "8   oÎµ          0.591679\n",
      "9   Î²Îµ          0.584800\n",
      "\n",
      "The top 10 similar words to Ï… are.\n",
      "    word  similarity score\n",
      "0     Î»âˆ—          0.571017\n",
      "1    Ï…dâˆ’          0.545640\n",
      "2     Â¯Î»          0.545279\n",
      "3  unity          0.538679\n",
      "4     hÎ»          0.525089\n",
      "5     zâˆ—          0.513141\n",
      "6     Âµâˆ—          0.511765\n",
      "7     Î±k          0.508589\n",
      "8    imÂµ          0.503652\n",
      "9     zÎ±          0.503012\n",
      "\n",
      "The top 10 similar words to âˆ‘ are.\n",
      "  word  similarity score\n",
      "0  xkâ‰¥          0.698180\n",
      "1   âˆ‘n          0.679918\n",
      "2  ï£¼ï£½ï£¾          0.678966\n",
      "3    âˆ          0.654144\n",
      "4  xij          0.653646\n",
      "5  ynâˆ’          0.653318\n",
      "6  xji          0.652631\n",
      "7   â‰¤i          0.640372\n",
      "8  ktk          0.610420\n",
      "9  ï£«ï£¬ï£­          0.607810\n",
      "\n",
      "The top 10 similar words to â‰« are.\n",
      "    word  similarity score\n",
      "0      â‰ª          0.710990\n",
      "1    wnÎ¶          0.678987\n",
      "2     cÎ´          0.640699\n",
      "3     Î´n          0.631502\n",
      "4   olog          0.629597\n",
      "5     nÎ¶          0.621507\n",
      "6  worse          0.612568\n",
      "7      â‰          0.610219\n",
      "8    bwâˆ—          0.606837\n",
      "9   bwnÎ¶          0.603547\n",
      "\n"
     ]
    }
   ],
   "source": [
    "translate = ['ğœ', 'ğ', 'âˆ', 'ğ›', 'ğ‘', 'Î¹', 'Î', 'ğŒ', 'ğšª', 'Î¥', 'ğœ‘', 'Î ', 'ğœ…', 'ğœ¸', 'Ï‘', 'ğ†', 'â¿', 'ğ›Š', 'ğœ‚', \n",
    "              'ğ›˜', 'ğ›»', 'ğ„', 'ğ', 'ğ˜', 'ğœ‰', 'ğ›Œ', 'Î²', 'ğ', 'ğœ·', 'â‰¤', 'ğœƒ', 'ğœ¹', 'Î›', 'âˆ€', 'ğ›', 'Ï‚', 'ğ›¿', 'ğ›', \n",
    "              'âˆ€', 'ğ', 'Î©', 'ğ››', 'ğ™', 'ğ›„', 'ğ›š', 'âˆˆ', 'ğ›', 'â‰ª', 'â‡', 'ğ›¾', 'ğŠ', 'Ç«', 'Î¸', 'âˆ', 'Î¶', 'ğœŒ', \n",
    "              'âˆ…', 'Î“', 'Ï†', 'ğœ¿', 'ğ›½', 'ğ•', 'ğœš', 'ğ›Ÿ', 'ğ“', 'Ï', 'Î»', 'Ïƒ', 'âˆª', '<', 'ğ›–', 'ğ›†', 'Î±', 'ğ›·', 'Î¿', 'Ï‡', \n",
    "              'ğœŠ', 'ğˆ', 'â‰©', 'ğ›', 'â†”', 'ğ›¡', 'Î·', 'Îœ', 'âŸ¾', 'âŠ¤' 'ğœ“', 'xi', 'âˆ´', 'âŠ†', 'Î—', 'ğ›ƒ', 'Î–', 'ğœ˜', \n",
    "              'â¤ƒ', 'ğ› ', 'Îº', 'Î¾', 'Ï‰', 'â‰¨', 'â„', 'ğœ•', 'Î', 'Î¨', 'â‰ˆ', 'Ï„', 'ğ›', 'ğ›‘', 'ğ‚', 'ğœ½', 'ğ›¥', 'â‡”', 'ğ›‡', 'âˆ¬', \n",
    "              'âŠƒ', 'ğœ’', 'ğ›‚', 'ğœ™', 'ğœ¼', 'Î´', 'ğœ¶', 'ğ›¬', '>', 'ğ’', 'ğœˆ', 'ğ›ˆ', 'ğ›¹', 'Î£', 'Ïˆ', 'ğ›‹', 'ğœ', 'Î™', 'â‰¡', 'Î¼', \n",
    "              'Î½', 'Î‘', 'ğ”', 'ğ€', 'ğœ', 'â¤‡', 'ğ›”', 'âŠ‡', 'â‡’', 'ğƒ', 'ğœ»', 'ğ›œ', 'âŠ‰', 'âŠˆ', 'âˆ‰', 'â‰ƒ', 'st', 'Î¡', 'ğ›“', 'ğœ‹', \n",
    "              'ğœ†', 'Î¤', 'ğœ‡', 'ğœ€', 'Âµ', 'ğœ¾', 'Ï€', 'âˆ‹', 'âŠ‚', 'âˆ«', 'Î’', 'âŠ…', 'Î§', 'âŠ„', 'ğœ', 'âˆµ', 'ğœ›', 'Â±', 'Â·', 'ğ›‰', \n",
    "              'ğœ', 'ğ', 'ğ›™', 'âˆ®', 'ğ‰', 'Î³', 'ğ›¼', 'âˆ†', 'Î”', 'ğœ„', 'ğ›—', 'ÎŸ', 'âˆ©', 'Îš', 'ğœº', 'ğœ—', 'rmÃ—n', 'ğœ', 'Î˜', \n",
    "              'âˆ‚', 'Î¦', 'âˆ§', 'ğœ–', 'ğ›¤', 'ğ‹', 'ğ‡', 'Îµ', 'Î•', 'Ï…', 'âˆ‘', 'ğ›…', 'ğ›’', 'â‰«', 'ğ…', 'ğ›•' ]\n",
    "for symbol in translate:\n",
    "    if symbol in model.wv.vocab:\n",
    "        similar = model.wv.most_similar(symbol, topn=10)\n",
    "        \n",
    "        print('The top 10 similar words to {0} are.'.format(symbol))\n",
    "        print(pd.DataFrame(similar, columns = ['word','similarity score']))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def pca_plot(model, word_set, title):\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    words_not_used = np.array([])\n",
    "    \n",
    "    for word in model.wv.vocab:\n",
    "        if word in word_set:\n",
    "            tokens.append(model[word])\n",
    "            labels.append(word)\n",
    "    \n",
    "    words_not_used = np.setdiff1d(word_set,np.array(labels))\n",
    "    \n",
    "    \n",
    "    pca = PCA(n_components=2) # Uses SVD\n",
    "    new_values = pca.fit_transform(tokens)\n",
    "    pca_ratio = pca.explained_variance_ratio_\n",
    "    print(pca_ratio)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "        \n",
    "    points = go.Scatter(\n",
    "        x = x,\n",
    "        y = y,\n",
    "        mode = 'markers+text',\n",
    "        text = labels,\n",
    "        textposition = 'top'\n",
    "    )\n",
    "\n",
    "    layout = go.Layout(\n",
    "        autosize=False,\n",
    "        width=800,\n",
    "        height=800,\n",
    "        title=title,\n",
    "        titlefont=dict(\n",
    "            size=25\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            showgrid=False,\n",
    "            zeroline=True,\n",
    "            showticklabels=False\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showgrid=False,\n",
    "            zeroline=True,\n",
    "            showticklabels=False\n",
    "        )\n",
    "    )\n",
    "\n",
    "    data = [points]\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "    py.offline.iplot(fig)\n",
    "    \n",
    "    return words_not_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20706032 0.08863876]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kendallgillies/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning:\n",
      "\n",
      "Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "markers+text",
         "text": [
          "matrix",
          "factorization",
          "patterns",
          "data",
          "sparse",
          "space",
          "gradient",
          "recall",
          "zero",
          "consistency",
          "mean",
          "nonlinearity",
          "computational",
          "matrix_factorization",
          "process",
          "kernel",
          "model",
          "gaussian",
          "features",
          "discrete",
          "nonlinear",
          "tree",
          "norm",
          "proof",
          "ensemble",
          "step",
          "logarithm",
          "interpolation",
          "uniformly",
          "derive",
          "dx",
          "coupling",
          "measure",
          "bernoulli",
          "orthogonal",
          "random_variable",
          "classification",
          "convex",
          "unbiased",
          "deterministic",
          "eigenvalue",
          "biased",
          "bias",
          "neighborhood",
          "jacobian",
          "optimization",
          "trajectory",
          "eigenvector",
          "tend",
          "probability_distribution",
          "step_size",
          "general_model",
          "euclidean_distance",
          "metric",
          "complexity",
          "dirichlet",
          "node",
          "linearly_independent",
          "accuracy",
          "modeling",
          "minimization",
          "threshold",
          "sampling",
          "hierarchical",
          "singular_value",
          "sufficient",
          "prior",
          "linear_combination",
          "roc",
          "conditional_distribution",
          "regularization",
          "prediction",
          "total_variation",
          "l_norm",
          "simulation_results",
          "entropy",
          "time_step",
          "poisson",
          "constrained",
          "target",
          "bootstrap",
          "cluster",
          "apriori",
          "correlation",
          "normalization",
          "stack",
          "batch",
          "binomial",
          "inertia",
          "concavity",
          "projected",
          "bayesian",
          "sensitivity",
          "markov_chain",
          "log_e",
          "monte_carlo",
          "precision",
          "adjusted",
          "likelihood",
          "convex_optimization",
          "fold",
          "training",
          "time_series",
          "greedy",
          "machine_learning",
          "normalize",
          "posterior",
          "lasso",
          "dimensionality",
          "parameter_estimation",
          "correlated",
          "linearly_dependent",
          "data_set",
          "cost_function",
          "dataset",
          "confidence",
          "pca",
          "specificity",
          "maximum_likelihood",
          "weight_vector",
          "python",
          "validation"
         ],
         "textposition": "top",
         "type": "scatter",
         "x": [
          -6.834231030510585,
          -1.5763407400643248,
          0.7736695288675034,
          -6.548919798378442,
          -2.9885684303286246,
          -9.4065568888611,
          -4.536954054476241,
          -5.66603328197871,
          -4.293027267875145,
          -2.189248648610185,
          -4.736910606039362,
          0.8900945352503303,
          -3.239219815173167,
          3.5126605115761182,
          -8.910313634852256,
          -6.583187410503624,
          -8.986849990448947,
          -5.748597516220053,
          0.9940822016096457,
          -6.14521016533755,
          -3.733499629829152,
          -3.1397038414538114,
          -6.725650641795518,
          -10.704700223614854,
          -0.3988043107063956,
          -6.616796449393067,
          1.2193739993313686,
          -1.2752518285254268,
          -5.004561337098065,
          -2.5058421059715754,
          -4.707264792912671,
          -2.705904194631891,
          -8.05352252628876,
          1.2881729536169537,
          -3.5378975522464313,
          10.903997968662793,
          -1.1268559985822268,
          -5.186057363975094,
          0.7667097508759181,
          -2.1216578990328854,
          -4.65705927228298,
          2.8141210850651692,
          -0.21276206811407042,
          -0.9175341465895344,
          -0.8778375050085245,
          -3.93377551809717,
          -0.4849192270582412,
          -0.8061115483451572,
          0.9641351935695074,
          6.865665132867074,
          6.299942499821559,
          4.693604556553342,
          5.592381533603543,
          -6.974049495699127,
          -4.951522068399936,
          -3.659938483421134,
          -2.928442282328382,
          8.264542800078571,
          -2.639420490051009,
          0.6082542259352091,
          -1.283818016750437,
          -0.9331312674956923,
          -1.8977843617251586,
          1.4066281861988752,
          5.653219096947158,
          -3.6710720769474205,
          -2.583557945425503,
          8.753480737633854,
          2.760505908372654,
          4.402512927509865,
          -1.3870367072336136,
          1.8315869542398169,
          7.441039539388326,
          5.70541974093776,
          5.2745036197051345,
          -5.879332368483822,
          7.923133975731278,
          -3.9035797574192213,
          -0.4005675784036492,
          -2.277579475554708,
          0.9604037631654009,
          -2.151708004054756,
          2.2335475704809684,
          -0.9129718116000816,
          -0.5255621914235865,
          2.077806234326338,
          2.565161564976691,
          0.33552251158047325,
          3.2176510408472736,
          2.646534073013796,
          1.905436404896072,
          -0.14710212604496842,
          -0.2735694431818749,
          6.9959194662638895,
          4.550711262119745,
          7.1756256560595535,
          1.0500311367619644,
          2.1124994346752493,
          0.3852691594597464,
          6.728754662228596,
          1.5292345640035658,
          2.39082043767684,
          4.076640765540451,
          2.389559246927489,
          5.020028755616833,
          1.9939892297942627,
          -0.5056138275971372,
          1.6008027530371918,
          2.2802399687606973,
          4.803969157823149,
          1.9202495764128402,
          3.619813211877851,
          7.447761181182161,
          6.733075871035364,
          0.6174559008644127,
          1.7418176882697707,
          1.3677560737945864,
          2.7312212663739364,
          4.561752794438654,
          3.8117401357187064,
          2.1793649001703423,
          2.349892456328819
         ],
         "y": [
          -3.1103755768042363,
          -1.6364809688251098,
          -2.7956750279320928,
          -3.679967375592595,
          -2.6113372766456577,
          10.672781219144738,
          1.6547748423455182,
          2.8253151336321327,
          1.0818932685135827,
          -1.7876853435059685,
          -0.1002880716948768,
          0.20543991393296654,
          -5.992554316854579,
          0.9145868176670819,
          -1.075815076313313,
          5.979319088394801,
          -4.796554218012116,
          2.907009676547766,
          -1.0487964600232353,
          0.34580888962116946,
          -1.2751998835024414,
          -7.03682171293721,
          7.707683898656168,
          -0.5069719809089686,
          -0.40350748859664304,
          -6.184232601926538,
          1.086132118793728,
          0.6020977237169993,
          2.3341228712814037,
          -1.5811043279871608,
          5.996907378303729,
          -2.4320522259774084,
          10.52999947693738,
          0.5989952459002684,
          4.159475546408864,
          2.2497110300882506,
          0.2511460635489843,
          2.7622474391273446,
          -1.8542466911712112,
          -2.1517550050503247,
          -0.06321346668321576,
          0.17020990731409189,
          -1.6710882691003663,
          1.98493223860494,
          1.5225454651868633,
          -5.249077291501451,
          -1.1923822892617968,
          -0.19808160070797118,
          -0.2215162602476444,
          1.4330192431002238,
          1.0662655767626614,
          0.947707537348708,
          1.1451090892272582,
          9.878818822517156,
          -2.811749699503526,
          3.7703457055507563,
          -7.4720646531796335,
          0.40883961119507517,
          -5.915735385096903,
          -2.4881552188551543,
          -1.6530256705100057,
          -2.3309226294477745,
          -3.4500527480316485,
          -2.4441083648531694,
          1.0885161207316723,
          -2.0486777811347747,
          -1.7971650541340083,
          1.2860214015444047,
          0.6768091684469251,
          0.5584269481332377,
          -0.5722924886890525,
          -1.0665648460592876,
          1.2309872429695925,
          0.7579515381662553,
          1.0986570442908443,
          2.5577461813707774,
          1.1638754534758438,
          2.8467493267986024,
          -0.9944043025624568,
          -1.922228230273398,
          -1.3942373593314557,
          -2.9950334789024136,
          0.22175033457363788,
          -1.2200956332238533,
          0.35009537686114184,
          1.4718020174420885,
          -0.4484704531339631,
          -0.38954933098093664,
          0.38057407446222324,
          0.955194394620292,
          0.2855370514281389,
          -2.699126054108824,
          -1.8776507157459288,
          1.5093175493092508,
          1.028316033089708,
          1.9385970319128882,
          -1.6758555158146422,
          -0.38562981521937023,
          -0.9128150019101605,
          1.4323594346583548,
          -0.8987182424924621,
          0.06727633268474156,
          0.9227152646067392,
          -0.18324423306665927,
          1.3754544034161655,
          1.0198836035747987,
          -0.46040206631484853,
          -1.3244415353077266,
          0.1758948273967788,
          1.1950403586746685,
          -0.5308092183045153,
          0.6130787733327854,
          0.9519052320637106,
          0.9769779022224956,
          -2.32999100218266,
          -0.8404212440883521,
          -0.35545304618163903,
          -0.1959819857751253,
          1.2599115189454813,
          0.744661611671871,
          -0.4118061607927852,
          -0.18166441927349097
         ]
        }
       ],
       "layout": {
        "autosize": false,
        "height": 800,
        "title": "Word2Vec: Mathematics",
        "titlefont": {
         "size": 25
        },
        "width": 800,
        "xaxis": {
         "showgrid": false,
         "showticklabels": false,
         "zeroline": true
        },
        "yaxis": {
         "showgrid": false,
         "showticklabels": false,
         "zeroline": true
        }
       }
      },
      "text/html": [
       "<div id=\"df3334db-d6f0-4028-b02c-5bc94a1fa5c6\" style=\"height: 800px; width: 800px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"df3334db-d6f0-4028-b02c-5bc94a1fa5c6\", [{\"type\": \"scatter\", \"x\": [-6.834231030510585, -1.5763407400643248, 0.7736695288675034, -6.548919798378442, -2.9885684303286246, -9.4065568888611, -4.536954054476241, -5.66603328197871, -4.293027267875145, -2.189248648610185, -4.736910606039362, 0.8900945352503303, -3.239219815173167, 3.5126605115761182, -8.910313634852256, -6.583187410503624, -8.986849990448947, -5.748597516220053, 0.9940822016096457, -6.14521016533755, -3.733499629829152, -3.1397038414538114, -6.725650641795518, -10.704700223614854, -0.3988043107063956, -6.616796449393067, 1.2193739993313686, -1.2752518285254268, -5.004561337098065, -2.5058421059715754, -4.707264792912671, -2.705904194631891, -8.05352252628876, 1.2881729536169537, -3.5378975522464313, 10.903997968662793, -1.1268559985822268, -5.186057363975094, 0.7667097508759181, -2.1216578990328854, -4.65705927228298, 2.8141210850651692, -0.21276206811407042, -0.9175341465895344, -0.8778375050085245, -3.93377551809717, -0.4849192270582412, -0.8061115483451572, 0.9641351935695074, 6.865665132867074, 6.299942499821559, 4.693604556553342, 5.592381533603543, -6.974049495699127, -4.951522068399936, -3.659938483421134, -2.928442282328382, 8.264542800078571, -2.639420490051009, 0.6082542259352091, -1.283818016750437, -0.9331312674956923, -1.8977843617251586, 1.4066281861988752, 5.653219096947158, -3.6710720769474205, -2.583557945425503, 8.753480737633854, 2.760505908372654, 4.402512927509865, -1.3870367072336136, 1.8315869542398169, 7.441039539388326, 5.70541974093776, 5.2745036197051345, -5.879332368483822, 7.923133975731278, -3.9035797574192213, -0.4005675784036492, -2.277579475554708, 0.9604037631654009, -2.151708004054756, 2.2335475704809684, -0.9129718116000816, -0.5255621914235865, 2.077806234326338, 2.565161564976691, 0.33552251158047325, 3.2176510408472736, 2.646534073013796, 1.905436404896072, -0.14710212604496842, -0.2735694431818749, 6.9959194662638895, 4.550711262119745, 7.1756256560595535, 1.0500311367619644, 2.1124994346752493, 0.3852691594597464, 6.728754662228596, 1.5292345640035658, 2.39082043767684, 4.076640765540451, 2.389559246927489, 5.020028755616833, 1.9939892297942627, -0.5056138275971372, 1.6008027530371918, 2.2802399687606973, 4.803969157823149, 1.9202495764128402, 3.619813211877851, 7.447761181182161, 6.733075871035364, 0.6174559008644127, 1.7418176882697707, 1.3677560737945864, 2.7312212663739364, 4.561752794438654, 3.8117401357187064, 2.1793649001703423, 2.349892456328819], \"y\": [-3.1103755768042363, -1.6364809688251098, -2.7956750279320928, -3.679967375592595, -2.6113372766456577, 10.672781219144738, 1.6547748423455182, 2.8253151336321327, 1.0818932685135827, -1.7876853435059685, -0.1002880716948768, 0.20543991393296654, -5.992554316854579, 0.9145868176670819, -1.075815076313313, 5.979319088394801, -4.796554218012116, 2.907009676547766, -1.0487964600232353, 0.34580888962116946, -1.2751998835024414, -7.03682171293721, 7.707683898656168, -0.5069719809089686, -0.40350748859664304, -6.184232601926538, 1.086132118793728, 0.6020977237169993, 2.3341228712814037, -1.5811043279871608, 5.996907378303729, -2.4320522259774084, 10.52999947693738, 0.5989952459002684, 4.159475546408864, 2.2497110300882506, 0.2511460635489843, 2.7622474391273446, -1.8542466911712112, -2.1517550050503247, -0.06321346668321576, 0.17020990731409189, -1.6710882691003663, 1.98493223860494, 1.5225454651868633, -5.249077291501451, -1.1923822892617968, -0.19808160070797118, -0.2215162602476444, 1.4330192431002238, 1.0662655767626614, 0.947707537348708, 1.1451090892272582, 9.878818822517156, -2.811749699503526, 3.7703457055507563, -7.4720646531796335, 0.40883961119507517, -5.915735385096903, -2.4881552188551543, -1.6530256705100057, -2.3309226294477745, -3.4500527480316485, -2.4441083648531694, 1.0885161207316723, -2.0486777811347747, -1.7971650541340083, 1.2860214015444047, 0.6768091684469251, 0.5584269481332377, -0.5722924886890525, -1.0665648460592876, 1.2309872429695925, 0.7579515381662553, 1.0986570442908443, 2.5577461813707774, 1.1638754534758438, 2.8467493267986024, -0.9944043025624568, -1.922228230273398, -1.3942373593314557, -2.9950334789024136, 0.22175033457363788, -1.2200956332238533, 0.35009537686114184, 1.4718020174420885, -0.4484704531339631, -0.38954933098093664, 0.38057407446222324, 0.955194394620292, 0.2855370514281389, -2.699126054108824, -1.8776507157459288, 1.5093175493092508, 1.028316033089708, 1.9385970319128882, -1.6758555158146422, -0.38562981521937023, -0.9128150019101605, 1.4323594346583548, -0.8987182424924621, 0.06727633268474156, 0.9227152646067392, -0.18324423306665927, 1.3754544034161655, 1.0198836035747987, -0.46040206631484853, -1.3244415353077266, 0.1758948273967788, 1.1950403586746685, -0.5308092183045153, 0.6130787733327854, 0.9519052320637106, 0.9769779022224956, -2.32999100218266, -0.8404212440883521, -0.35545304618163903, -0.1959819857751253, 1.2599115189454813, 0.744661611671871, -0.4118061607927852, -0.18166441927349097], \"mode\": \"markers+text\", \"text\": [\"matrix\", \"factorization\", \"patterns\", \"data\", \"sparse\", \"space\", \"gradient\", \"recall\", \"zero\", \"consistency\", \"mean\", \"nonlinearity\", \"computational\", \"matrix_factorization\", \"process\", \"kernel\", \"model\", \"gaussian\", \"features\", \"discrete\", \"nonlinear\", \"tree\", \"norm\", \"proof\", \"ensemble\", \"step\", \"logarithm\", \"interpolation\", \"uniformly\", \"derive\", \"dx\", \"coupling\", \"measure\", \"bernoulli\", \"orthogonal\", \"random_variable\", \"classification\", \"convex\", \"unbiased\", \"deterministic\", \"eigenvalue\", \"biased\", \"bias\", \"neighborhood\", \"jacobian\", \"optimization\", \"trajectory\", \"eigenvector\", \"tend\", \"probability_distribution\", \"step_size\", \"general_model\", \"euclidean_distance\", \"metric\", \"complexity\", \"dirichlet\", \"node\", \"linearly_independent\", \"accuracy\", \"modeling\", \"minimization\", \"threshold\", \"sampling\", \"hierarchical\", \"singular_value\", \"sufficient\", \"prior\", \"linear_combination\", \"roc\", \"conditional_distribution\", \"regularization\", \"prediction\", \"total_variation\", \"l_norm\", \"simulation_results\", \"entropy\", \"time_step\", \"poisson\", \"constrained\", \"target\", \"bootstrap\", \"cluster\", \"apriori\", \"correlation\", \"normalization\", \"stack\", \"batch\", \"binomial\", \"inertia\", \"concavity\", \"projected\", \"bayesian\", \"sensitivity\", \"markov_chain\", \"log_e\", \"monte_carlo\", \"precision\", \"adjusted\", \"likelihood\", \"convex_optimization\", \"fold\", \"training\", \"time_series\", \"greedy\", \"machine_learning\", \"normalize\", \"posterior\", \"lasso\", \"dimensionality\", \"parameter_estimation\", \"correlated\", \"linearly_dependent\", \"data_set\", \"cost_function\", \"dataset\", \"confidence\", \"pca\", \"specificity\", \"maximum_likelihood\", \"weight_vector\", \"python\", \"validation\"], \"textposition\": \"top\"}], {\"autosize\": false, \"width\": 800, \"height\": 800, \"title\": \"Word2Vec: Mathematics\", \"titlefont\": {\"size\": 25}, \"xaxis\": {\"showgrid\": false, \"zeroline\": true, \"showticklabels\": false}, \"yaxis\": {\"showgrid\": false, \"zeroline\": true, \"showticklabels\": false}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"df3334db-d6f0-4028-b02c-5bc94a1fa5c6\" style=\"height: 800px; width: 800px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"df3334db-d6f0-4028-b02c-5bc94a1fa5c6\", [{\"type\": \"scatter\", \"x\": [-6.834231030510585, -1.5763407400643248, 0.7736695288675034, -6.548919798378442, -2.9885684303286246, -9.4065568888611, -4.536954054476241, -5.66603328197871, -4.293027267875145, -2.189248648610185, -4.736910606039362, 0.8900945352503303, -3.239219815173167, 3.5126605115761182, -8.910313634852256, -6.583187410503624, -8.986849990448947, -5.748597516220053, 0.9940822016096457, -6.14521016533755, -3.733499629829152, -3.1397038414538114, -6.725650641795518, -10.704700223614854, -0.3988043107063956, -6.616796449393067, 1.2193739993313686, -1.2752518285254268, -5.004561337098065, -2.5058421059715754, -4.707264792912671, -2.705904194631891, -8.05352252628876, 1.2881729536169537, -3.5378975522464313, 10.903997968662793, -1.1268559985822268, -5.186057363975094, 0.7667097508759181, -2.1216578990328854, -4.65705927228298, 2.8141210850651692, -0.21276206811407042, -0.9175341465895344, -0.8778375050085245, -3.93377551809717, -0.4849192270582412, -0.8061115483451572, 0.9641351935695074, 6.865665132867074, 6.299942499821559, 4.693604556553342, 5.592381533603543, -6.974049495699127, -4.951522068399936, -3.659938483421134, -2.928442282328382, 8.264542800078571, -2.639420490051009, 0.6082542259352091, -1.283818016750437, -0.9331312674956923, -1.8977843617251586, 1.4066281861988752, 5.653219096947158, -3.6710720769474205, -2.583557945425503, 8.753480737633854, 2.760505908372654, 4.402512927509865, -1.3870367072336136, 1.8315869542398169, 7.441039539388326, 5.70541974093776, 5.2745036197051345, -5.879332368483822, 7.923133975731278, -3.9035797574192213, -0.4005675784036492, -2.277579475554708, 0.9604037631654009, -2.151708004054756, 2.2335475704809684, -0.9129718116000816, -0.5255621914235865, 2.077806234326338, 2.565161564976691, 0.33552251158047325, 3.2176510408472736, 2.646534073013796, 1.905436404896072, -0.14710212604496842, -0.2735694431818749, 6.9959194662638895, 4.550711262119745, 7.1756256560595535, 1.0500311367619644, 2.1124994346752493, 0.3852691594597464, 6.728754662228596, 1.5292345640035658, 2.39082043767684, 4.076640765540451, 2.389559246927489, 5.020028755616833, 1.9939892297942627, -0.5056138275971372, 1.6008027530371918, 2.2802399687606973, 4.803969157823149, 1.9202495764128402, 3.619813211877851, 7.447761181182161, 6.733075871035364, 0.6174559008644127, 1.7418176882697707, 1.3677560737945864, 2.7312212663739364, 4.561752794438654, 3.8117401357187064, 2.1793649001703423, 2.349892456328819], \"y\": [-3.1103755768042363, -1.6364809688251098, -2.7956750279320928, -3.679967375592595, -2.6113372766456577, 10.672781219144738, 1.6547748423455182, 2.8253151336321327, 1.0818932685135827, -1.7876853435059685, -0.1002880716948768, 0.20543991393296654, -5.992554316854579, 0.9145868176670819, -1.075815076313313, 5.979319088394801, -4.796554218012116, 2.907009676547766, -1.0487964600232353, 0.34580888962116946, -1.2751998835024414, -7.03682171293721, 7.707683898656168, -0.5069719809089686, -0.40350748859664304, -6.184232601926538, 1.086132118793728, 0.6020977237169993, 2.3341228712814037, -1.5811043279871608, 5.996907378303729, -2.4320522259774084, 10.52999947693738, 0.5989952459002684, 4.159475546408864, 2.2497110300882506, 0.2511460635489843, 2.7622474391273446, -1.8542466911712112, -2.1517550050503247, -0.06321346668321576, 0.17020990731409189, -1.6710882691003663, 1.98493223860494, 1.5225454651868633, -5.249077291501451, -1.1923822892617968, -0.19808160070797118, -0.2215162602476444, 1.4330192431002238, 1.0662655767626614, 0.947707537348708, 1.1451090892272582, 9.878818822517156, -2.811749699503526, 3.7703457055507563, -7.4720646531796335, 0.40883961119507517, -5.915735385096903, -2.4881552188551543, -1.6530256705100057, -2.3309226294477745, -3.4500527480316485, -2.4441083648531694, 1.0885161207316723, -2.0486777811347747, -1.7971650541340083, 1.2860214015444047, 0.6768091684469251, 0.5584269481332377, -0.5722924886890525, -1.0665648460592876, 1.2309872429695925, 0.7579515381662553, 1.0986570442908443, 2.5577461813707774, 1.1638754534758438, 2.8467493267986024, -0.9944043025624568, -1.922228230273398, -1.3942373593314557, -2.9950334789024136, 0.22175033457363788, -1.2200956332238533, 0.35009537686114184, 1.4718020174420885, -0.4484704531339631, -0.38954933098093664, 0.38057407446222324, 0.955194394620292, 0.2855370514281389, -2.699126054108824, -1.8776507157459288, 1.5093175493092508, 1.028316033089708, 1.9385970319128882, -1.6758555158146422, -0.38562981521937023, -0.9128150019101605, 1.4323594346583548, -0.8987182424924621, 0.06727633268474156, 0.9227152646067392, -0.18324423306665927, 1.3754544034161655, 1.0198836035747987, -0.46040206631484853, -1.3244415353077266, 0.1758948273967788, 1.1950403586746685, -0.5308092183045153, 0.6130787733327854, 0.9519052320637106, 0.9769779022224956, -2.32999100218266, -0.8404212440883521, -0.35545304618163903, -0.1959819857751253, 1.2599115189454813, 0.744661611671871, -0.4118061607927852, -0.18166441927349097], \"mode\": \"markers+text\", \"text\": [\"matrix\", \"factorization\", \"patterns\", \"data\", \"sparse\", \"space\", \"gradient\", \"recall\", \"zero\", \"consistency\", \"mean\", \"nonlinearity\", \"computational\", \"matrix_factorization\", \"process\", \"kernel\", \"model\", \"gaussian\", \"features\", \"discrete\", \"nonlinear\", \"tree\", \"norm\", \"proof\", \"ensemble\", \"step\", \"logarithm\", \"interpolation\", \"uniformly\", \"derive\", \"dx\", \"coupling\", \"measure\", \"bernoulli\", \"orthogonal\", \"random_variable\", \"classification\", \"convex\", \"unbiased\", \"deterministic\", \"eigenvalue\", \"biased\", \"bias\", \"neighborhood\", \"jacobian\", \"optimization\", \"trajectory\", \"eigenvector\", \"tend\", \"probability_distribution\", \"step_size\", \"general_model\", \"euclidean_distance\", \"metric\", \"complexity\", \"dirichlet\", \"node\", \"linearly_independent\", \"accuracy\", \"modeling\", \"minimization\", \"threshold\", \"sampling\", \"hierarchical\", \"singular_value\", \"sufficient\", \"prior\", \"linear_combination\", \"roc\", \"conditional_distribution\", \"regularization\", \"prediction\", \"total_variation\", \"l_norm\", \"simulation_results\", \"entropy\", \"time_step\", \"poisson\", \"constrained\", \"target\", \"bootstrap\", \"cluster\", \"apriori\", \"correlation\", \"normalization\", \"stack\", \"batch\", \"binomial\", \"inertia\", \"concavity\", \"projected\", \"bayesian\", \"sensitivity\", \"markov_chain\", \"log_e\", \"monte_carlo\", \"precision\", \"adjusted\", \"likelihood\", \"convex_optimization\", \"fold\", \"training\", \"time_series\", \"greedy\", \"machine_learning\", \"normalize\", \"posterior\", \"lasso\", \"dimensionality\", \"parameter_estimation\", \"correlated\", \"linearly_dependent\", \"data_set\", \"cost_function\", \"dataset\", \"confidence\", \"pca\", \"specificity\", \"maximum_likelihood\", \"weight_vector\", \"python\", \"validation\"], \"textposition\": \"top\"}], {\"autosize\": false, \"width\": 800, \"height\": 800, \"title\": \"Word2Vec: Mathematics\", \"titlefont\": {\"size\": 25}, \"xaxis\": {\"showgrid\": false, \"zeroline\": true, \"showticklabels\": false}, \"yaxis\": {\"showgrid\": false, \"zeroline\": true, \"showticklabels\": false}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words not in interesting list not used:\n",
      "ab_testing, activation_function, adaboost, adaptive_boosting, agglomerative, aggregate, aggregates, aggregating, analysis_pca, analyst, auc, average_linkage, backpropagation, bag_of_words, bag_words, bagging, belief, big_data, boost, brute_force, cart, classifier, cod, complete_linkage, component_analysis, confusion_matrix, cosine_distance, cosine_similarity, cross_validate, cross_validation, curse_dimensionality, curse_of_dimensionality, data_engineering, data_mining, data_processing, dbscan, decision_boundary, decision_tree, deep_learning, dimensionality_reduction, downsampled, elastic_net, engineer, f1, f1_score, f_score, fbeta_score, feature_extraction, feature_representation, feature_selection, feature_space, feature_vector, feedforward, fpr, fscore, functionality, gaussian_model, gaussians, generalized_linear_model, generative, gradient_boosting, gradient_descent, hidden_layer, hierarchical_agglomerative_clustering, hierarchical_clustering, high_confidence, information_entropy, interconnected, interpretability, jaccard_distance, k_iterations, k_means, kmeans, knn, l_regularization, labeled_data, lambda, language_processing, latent_dirichlet_allocation, lda, learning_algorithms, learning_rate, likelihood_estimation, linear_approximation, linear_model, linear_regression, linear_term, linkage, log_likelihood, log_odd, logistic_regression, logit, loss_function, manhattan_distance, mathematical_model, mean_squared_error, mini_batch, minibatch, missing_data, mle, model_based, model_complexity, model_predictive, model_training, multiple_correspondence_analysis, n_gram, naive_bayes, natural_language_processing, nearest_neighbor, nearestneighbor, negative_loglikelihood, neural_network, ngram, nlp, ols, optimal_solutions, ordinary_least_squares, outlier, parameterization, parametric_model, pattern_recognition, performance_metric, pipeline, polynomial_regression, pooling, predictive, predictor, principal_component, principal_component_analysis, prune, random_forest, receiver_operating_characteristic, regression_model, regularization_parameter, ridge_regression, semisupervised, sigmoid, simple_linear, single_linkage, singular_value_decomposition, skewed, spectral_clustering, statistical_model, stemming, stochastic_gradient, stochastic_gradient_descent, stop_word, stopping_criterion, subsampling, supervised_learning, support_vector, support_vector_machines, svd, svm, test_data, tokenization, tokenize, topic_modeling, tpr, train, trained_model, trained_models, training_data, training_model, training_validation, treelike, tsne, uncorrelated, unsupervised, unsupervised_learning, upsampling, validate, variance_reduction, vector_regression, visualization, ward, ward_linkage, word_embedding, wordvec\n"
     ]
    }
   ],
   "source": [
    "words_not_used = pca_plot(model, interesting_words,'Word2Vec: Interesting Words')\n",
    "print('Words not in interesting list not used:')\n",
    "print(', '.join(words_not_used))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08868276 0.06068073]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kendallgillies/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning:\n",
      "\n",
      "Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "markers+text",
         "text": [
          "â‰ˆ",
          "Îµ",
          "Î¾",
          "Î»",
          "Î½",
          "Ï†",
          "Î²",
          "âˆª",
          "âˆˆ",
          "â‰¤",
          "Â±",
          "Î³",
          "âˆ",
          "âˆ’âˆ",
          "xi",
          "Â·",
          "Ï„",
          "â‰¡",
          "Ï",
          "âŠ‚",
          "Î´",
          "Î±",
          "âˆ‚",
          "âˆ€",
          "âŠ†",
          "st",
          "Ïˆ",
          "Âµ",
          "Ïƒ",
          "â‡’",
          "âˆ§",
          "Îº",
          "Î·",
          "Ï€",
          "âˆ©",
          "âˆ…",
          "Ï‰",
          "Î¶",
          "Î¸",
          "âˆ†",
          "Ï‡",
          "âŠ•",
          "Ï…",
          "â‡”",
          "rmÃ—n",
          "Ç«",
          "â‰ƒ",
          "âˆ‘",
          "Ï‘",
          "âˆ‹",
          "wt",
          "Ï‚",
          "âŠƒ",
          "â‰ª",
          "Î¹",
          "âŠ‡",
          "â†”",
          "â‰«"
         ],
         "textposition": "top",
         "type": "scatter",
         "x": [
          -2.6738536693888437,
          -3.084115291984402,
          -7.349759995962469,
          -2.8107001060859367,
          -3.7848359568137244,
          -3.398378484836484,
          -2.3416330455078396,
          7.578790755632707,
          2.086443712217595,
          -1.8609388145333943,
          -0.7984433188127343,
          -4.497913693111411,
          -4.394818154790457,
          -0.9248255584374391,
          -0.7533035260331067,
          0.843432237509177,
          -2.240571906587787,
          -2.3212325899176043,
          -4.694627190168655,
          7.2888872147581685,
          -2.9260615552969123,
          -2.4515197082704128,
          1.242890017117904,
          0.9539727412423223,
          10.74674425367456,
          -0.764900995867503,
          -4.886790214275618,
          -3.2886287940339236,
          -1.084128390907331,
          4.944352979446203,
          1.0489872722857276,
          -4.469651083193635,
          -7.33885974180911,
          -1.908976187286709,
          9.581845891499801,
          10.634033156332151,
          -2.0976486248601107,
          -4.177437619346747,
          -2.5887525064028813,
          4.961615768068708,
          -4.536944489438891,
          5.59921190687915,
          0.1705774420241464,
          4.119540628464428,
          1.3114219757648455,
          -3.2938736274117586,
          5.18845733636034,
          0.34903263564631215,
          -3.499163108243967,
          0.9160496684450866,
          -1.2445125598046392,
          0.554697965903939,
          7.4737905413952115,
          -1.049631221370987,
          3.312390975964015,
          6.6779906530466455,
          1.943881122559298,
          0.008392878554972226
         ],
         "y": [
          2.5834904322802443,
          -0.9857827643560018,
          -1.0918866104688851,
          -1.3280913047691962,
          -4.307102234666651,
          2.305592754926483,
          -3.8694045943062783,
          -3.9818331172385952,
          -4.030814473230256,
          -3.8711649880152574,
          3.8801831212043103,
          -4.012961343782852,
          -3.554340819873753,
          -1.912683832755875,
          -0.6141164876660234,
          0.510365374230411,
          -0.42098384159812674,
          4.625143774034712,
          -3.0493332408535947,
          -4.808054788254684,
          -5.835057621600983,
          -5.352717025313611,
          2.0354444284092197,
          -0.07697353587746675,
          -5.039003575809578,
          1.6745646684355864,
          2.7162188229458053,
          -2.92232090737644,
          -1.343846268835669,
          -0.6548264048089658,
          2.934458276105954,
          -4.663903165624282,
          -0.40487936714394107,
          -1.4452505629075583,
          -6.289916644620162,
          -4.542723803441427,
          -2.216792652413859,
          1.444897728064235,
          -1.1770242055100464,
          -2.4431503557032994,
          7.336977766888612,
          6.949173662079808,
          2.1335258056123467,
          2.926377712419425,
          3.970962705867879,
          -2.7136246177701233,
          7.142873714711688,
          4.620406293296044,
          1.9021664119691484,
          4.53677841202653,
          1.5090296878545706,
          4.041995681274446,
          1.3629660507504815,
          1.084468268760763,
          5.268722173394955,
          2.682788846717131,
          3.960071633722289,
          2.8209209486103988
         ]
        }
       ],
       "layout": {
        "autosize": false,
        "height": 800,
        "title": "Word2Vec: Mathematics - Characters",
        "titlefont": {
         "size": 25
        },
        "width": 800,
        "xaxis": {
         "showgrid": false,
         "showticklabels": false,
         "zeroline": true
        },
        "yaxis": {
         "showgrid": false,
         "showticklabels": false,
         "zeroline": true
        }
       }
      },
      "text/html": [
       "<div id=\"ab46bd77-3dac-4a6a-a473-418c6c536d48\" style=\"height: 800px; width: 800px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"ab46bd77-3dac-4a6a-a473-418c6c536d48\", [{\"type\": \"scatter\", \"x\": [-2.6738536693888437, -3.084115291984402, -7.349759995962469, -2.8107001060859367, -3.7848359568137244, -3.398378484836484, -2.3416330455078396, 7.578790755632707, 2.086443712217595, -1.8609388145333943, -0.7984433188127343, -4.497913693111411, -4.394818154790457, -0.9248255584374391, -0.7533035260331067, 0.843432237509177, -2.240571906587787, -2.3212325899176043, -4.694627190168655, 7.2888872147581685, -2.9260615552969123, -2.4515197082704128, 1.242890017117904, 0.9539727412423223, 10.74674425367456, -0.764900995867503, -4.886790214275618, -3.2886287940339236, -1.084128390907331, 4.944352979446203, 1.0489872722857276, -4.469651083193635, -7.33885974180911, -1.908976187286709, 9.581845891499801, 10.634033156332151, -2.0976486248601107, -4.177437619346747, -2.5887525064028813, 4.961615768068708, -4.536944489438891, 5.59921190687915, 0.1705774420241464, 4.119540628464428, 1.3114219757648455, -3.2938736274117586, 5.18845733636034, 0.34903263564631215, -3.499163108243967, 0.9160496684450866, -1.2445125598046392, 0.554697965903939, 7.4737905413952115, -1.049631221370987, 3.312390975964015, 6.6779906530466455, 1.943881122559298, 0.008392878554972226], \"y\": [2.5834904322802443, -0.9857827643560018, -1.0918866104688851, -1.3280913047691962, -4.307102234666651, 2.305592754926483, -3.8694045943062783, -3.9818331172385952, -4.030814473230256, -3.8711649880152574, 3.8801831212043103, -4.012961343782852, -3.554340819873753, -1.912683832755875, -0.6141164876660234, 0.510365374230411, -0.42098384159812674, 4.625143774034712, -3.0493332408535947, -4.808054788254684, -5.835057621600983, -5.352717025313611, 2.0354444284092197, -0.07697353587746675, -5.039003575809578, 1.6745646684355864, 2.7162188229458053, -2.92232090737644, -1.343846268835669, -0.6548264048089658, 2.934458276105954, -4.663903165624282, -0.40487936714394107, -1.4452505629075583, -6.289916644620162, -4.542723803441427, -2.216792652413859, 1.444897728064235, -1.1770242055100464, -2.4431503557032994, 7.336977766888612, 6.949173662079808, 2.1335258056123467, 2.926377712419425, 3.970962705867879, -2.7136246177701233, 7.142873714711688, 4.620406293296044, 1.9021664119691484, 4.53677841202653, 1.5090296878545706, 4.041995681274446, 1.3629660507504815, 1.084468268760763, 5.268722173394955, 2.682788846717131, 3.960071633722289, 2.8209209486103988], \"mode\": \"markers+text\", \"text\": [\"\\u2248\", \"\\u03b5\", \"\\u03be\", \"\\u03bb\", \"\\u03bd\", \"\\u03c6\", \"\\u03b2\", \"\\u222a\", \"\\u2208\", \"\\u2264\", \"\\u00b1\", \"\\u03b3\", \"\\u221e\", \"\\u2212\\u221e\", \"xi\", \"\\u00b7\", \"\\u03c4\", \"\\u2261\", \"\\u03c1\", \"\\u2282\", \"\\u03b4\", \"\\u03b1\", \"\\u2202\", \"\\u2200\", \"\\u2286\", \"st\", \"\\u03c8\", \"\\u00b5\", \"\\u03c3\", \"\\u21d2\", \"\\u2227\", \"\\u03ba\", \"\\u03b7\", \"\\u03c0\", \"\\u2229\", \"\\u2205\", \"\\u03c9\", \"\\u03b6\", \"\\u03b8\", \"\\u2206\", \"\\u03c7\", \"\\u2295\", \"\\u03c5\", \"\\u21d4\", \"rm\\u00d7n\", \"\\u01eb\", \"\\u2243\", \"\\u2211\", \"\\u03d1\", \"\\u220b\", \"wt\", \"\\u03c2\", \"\\u2283\", \"\\u226a\", \"\\u03b9\", \"\\u2287\", \"\\u2194\", \"\\u226b\"], \"textposition\": \"top\"}], {\"autosize\": false, \"width\": 800, \"height\": 800, \"title\": \"Word2Vec: Mathematics - Characters\", \"titlefont\": {\"size\": 25}, \"xaxis\": {\"showgrid\": false, \"zeroline\": true, \"showticklabels\": false}, \"yaxis\": {\"showgrid\": false, \"zeroline\": true, \"showticklabels\": false}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"ab46bd77-3dac-4a6a-a473-418c6c536d48\" style=\"height: 800px; width: 800px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"ab46bd77-3dac-4a6a-a473-418c6c536d48\", [{\"type\": \"scatter\", \"x\": [-2.6738536693888437, -3.084115291984402, -7.349759995962469, -2.8107001060859367, -3.7848359568137244, -3.398378484836484, -2.3416330455078396, 7.578790755632707, 2.086443712217595, -1.8609388145333943, -0.7984433188127343, -4.497913693111411, -4.394818154790457, -0.9248255584374391, -0.7533035260331067, 0.843432237509177, -2.240571906587787, -2.3212325899176043, -4.694627190168655, 7.2888872147581685, -2.9260615552969123, -2.4515197082704128, 1.242890017117904, 0.9539727412423223, 10.74674425367456, -0.764900995867503, -4.886790214275618, -3.2886287940339236, -1.084128390907331, 4.944352979446203, 1.0489872722857276, -4.469651083193635, -7.33885974180911, -1.908976187286709, 9.581845891499801, 10.634033156332151, -2.0976486248601107, -4.177437619346747, -2.5887525064028813, 4.961615768068708, -4.536944489438891, 5.59921190687915, 0.1705774420241464, 4.119540628464428, 1.3114219757648455, -3.2938736274117586, 5.18845733636034, 0.34903263564631215, -3.499163108243967, 0.9160496684450866, -1.2445125598046392, 0.554697965903939, 7.4737905413952115, -1.049631221370987, 3.312390975964015, 6.6779906530466455, 1.943881122559298, 0.008392878554972226], \"y\": [2.5834904322802443, -0.9857827643560018, -1.0918866104688851, -1.3280913047691962, -4.307102234666651, 2.305592754926483, -3.8694045943062783, -3.9818331172385952, -4.030814473230256, -3.8711649880152574, 3.8801831212043103, -4.012961343782852, -3.554340819873753, -1.912683832755875, -0.6141164876660234, 0.510365374230411, -0.42098384159812674, 4.625143774034712, -3.0493332408535947, -4.808054788254684, -5.835057621600983, -5.352717025313611, 2.0354444284092197, -0.07697353587746675, -5.039003575809578, 1.6745646684355864, 2.7162188229458053, -2.92232090737644, -1.343846268835669, -0.6548264048089658, 2.934458276105954, -4.663903165624282, -0.40487936714394107, -1.4452505629075583, -6.289916644620162, -4.542723803441427, -2.216792652413859, 1.444897728064235, -1.1770242055100464, -2.4431503557032994, 7.336977766888612, 6.949173662079808, 2.1335258056123467, 2.926377712419425, 3.970962705867879, -2.7136246177701233, 7.142873714711688, 4.620406293296044, 1.9021664119691484, 4.53677841202653, 1.5090296878545706, 4.041995681274446, 1.3629660507504815, 1.084468268760763, 5.268722173394955, 2.682788846717131, 3.960071633722289, 2.8209209486103988], \"mode\": \"markers+text\", \"text\": [\"\\u2248\", \"\\u03b5\", \"\\u03be\", \"\\u03bb\", \"\\u03bd\", \"\\u03c6\", \"\\u03b2\", \"\\u222a\", \"\\u2208\", \"\\u2264\", \"\\u00b1\", \"\\u03b3\", \"\\u221e\", \"\\u2212\\u221e\", \"xi\", \"\\u00b7\", \"\\u03c4\", \"\\u2261\", \"\\u03c1\", \"\\u2282\", \"\\u03b4\", \"\\u03b1\", \"\\u2202\", \"\\u2200\", \"\\u2286\", \"st\", \"\\u03c8\", \"\\u00b5\", \"\\u03c3\", \"\\u21d2\", \"\\u2227\", \"\\u03ba\", \"\\u03b7\", \"\\u03c0\", \"\\u2229\", \"\\u2205\", \"\\u03c9\", \"\\u03b6\", \"\\u03b8\", \"\\u2206\", \"\\u03c7\", \"\\u2295\", \"\\u03c5\", \"\\u21d4\", \"rm\\u00d7n\", \"\\u01eb\", \"\\u2243\", \"\\u2211\", \"\\u03d1\", \"\\u220b\", \"wt\", \"\\u03c2\", \"\\u2283\", \"\\u226a\", \"\\u03b9\", \"\\u2287\", \"\\u2194\", \"\\u226b\"], \"textposition\": \"top\"}], {\"autosize\": false, \"width\": 800, \"height\": 800, \"title\": \"Word2Vec: Mathematics - Characters\", \"titlefont\": {\"size\": 25}, \"xaxis\": {\"showgrid\": false, \"zeroline\": true, \"showticklabels\": false}, \"yaxis\": {\"showgrid\": false, \"zeroline\": true, \"showticklabels\": false}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters not used:\n",
      " , <, >, Î‘, Î’, Î“, Î”, Î•, Î–, Î—, Î˜, Î™, Îš, Î›, Îœ, Î, Î, ÎŸ, Î , Î¡, Î£, Î¤, Î¥, Î¦, Î§, Î¨, Î©, Î¼, Î¿, â„, â‡, âˆ‰, âˆ, âˆ«, âˆ¬, âˆ®, âˆ´, âˆµ, â‰¨, â‰©, âŠ„, âŠ…, âŠˆ, âŠ‰, âŠ¤, â¿, âŸ¾, â¤ƒ, â¤‡, ğšª, ğ›‚, ğ›ƒ, ğ›„, ğ›…, ğ›†, ğ›‡, ğ›ˆ, ğ›‰, ğ›Š, ğ›‹, ğ›Œ, ğ›, ğ›, ğ›, ğ›, ğ›‘, ğ›’, ğ›“, ğ›”, ğ›•, ğ›–, ğ›—, ğ›˜, ğ›™, ğ›š, ğ››, ğ›œ, ğ›, ğ›, ğ›Ÿ, ğ› , ğ›¡, ğ›¤, ğ›¥, ğ›¬, ğ›·, ğ›¹, ğ›», ğ›¼, ğ›½, ğ›¾, ğ›¿, ğœ€, ğœ, ğœ‚, ğœƒ, ğœ„, ğœ…, ğœ†, ğœ‡, ğœˆ, ğœ‰, ğœŠ, ğœ‹, ğœŒ, ğœ, ğœ, ğœ, ğœ, ğœ‘, ğœ’, ğœ“, ğœ•, ğœ–, ğœ—, ğœ˜, ğœ™, ğœš, ğœ›, ğœ, ğœ¶, ğœ·, ğœ¸, ğœ¹, ğœº, ğœ», ğœ¼, ğœ½, ğœ¾, ğœ¿, ğ€, ğ, ğ‚, ğƒ, ğ„, ğ…, ğ†, ğ‡, ğˆ, ğ‰, ğŠ, ğ‹, ğŒ, ğ, ğ, ğ, ğ, ğ‘, ğ’, ğ“, ğ”, ğ•, ğ˜, ğ™\n"
     ]
    }
   ],
   "source": [
    "chars_not_used = pca_plot(model, characters,'Word2Vec: Characters')\n",
    "print('Characters not used:')\n",
    "print(', '.join(chars_not_used))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
